{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('base': conda)",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id    loan_amnt     term  interest_rate grade employment_length  \\\n",
       "0   0   609.296068  3 years       8.421982    A5           0 years   \n",
       "1   1  1183.266999  5 years      10.286776    B1          10 years   \n",
       "2   2   695.783256  3 years      14.723425    C2            1 year   \n",
       "3   3   738.392546  3 years      14.260708    C1           0 years   \n",
       "4   4  1642.400654  5 years      25.217452    E5          10 years   \n",
       "\n",
       "              purpose  credit_score application_type loan_status  \n",
       "0  debt_consolidation    714.061803       Individual   FullyPaid  \n",
       "1         credit_card    697.706701       Individual  ChargedOff  \n",
       "2  debt_consolidation    656.419357       Individual   FullyPaid  \n",
       "3         credit_card    657.906852       Individual   FullyPaid  \n",
       "4  debt_consolidation    662.972297       Individual   FullyPaid  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>loan_amnt</th>\n      <th>term</th>\n      <th>interest_rate</th>\n      <th>grade</th>\n      <th>employment_length</th>\n      <th>purpose</th>\n      <th>credit_score</th>\n      <th>application_type</th>\n      <th>loan_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>609.296068</td>\n      <td>3 years</td>\n      <td>8.421982</td>\n      <td>A5</td>\n      <td>0 years</td>\n      <td>debt_consolidation</td>\n      <td>714.061803</td>\n      <td>Individual</td>\n      <td>FullyPaid</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1183.266999</td>\n      <td>5 years</td>\n      <td>10.286776</td>\n      <td>B1</td>\n      <td>10 years</td>\n      <td>credit_card</td>\n      <td>697.706701</td>\n      <td>Individual</td>\n      <td>ChargedOff</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>695.783256</td>\n      <td>3 years</td>\n      <td>14.723425</td>\n      <td>C2</td>\n      <td>1 year</td>\n      <td>debt_consolidation</td>\n      <td>656.419357</td>\n      <td>Individual</td>\n      <td>FullyPaid</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>738.392546</td>\n      <td>3 years</td>\n      <td>14.260708</td>\n      <td>C1</td>\n      <td>0 years</td>\n      <td>credit_card</td>\n      <td>657.906852</td>\n      <td>Individual</td>\n      <td>FullyPaid</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1642.400654</td>\n      <td>5 years</td>\n      <td>25.217452</td>\n      <td>E5</td>\n      <td>10 years</td>\n      <td>debt_consolidation</td>\n      <td>662.972297</td>\n      <td>Individual</td>\n      <td>FullyPaid</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 253
    }
   ],
   "source": [
    "# Chapter1\n",
    "# NN構築試行\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score  # モデルの評価を行うための関数\n",
    "# 学習データ読み込み\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Chapter2\n",
    "# 学習の再現を行うために乱数シードを固定するためのコード\n",
    "import os\n",
    "import random as rn\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(0)\n",
    "rn.seed(0)\n",
    "\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph())\n",
    "K.set_session(sess)\n",
    "\n",
    "pd.set_option(\"max_columns\", None)\n",
    "# pd.set_option('max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"デフォルトした人:\", len(data[data[\"loan_status\"]==\"ChargedOff\"]))\n",
    "# print(\"デフォルトしていない人:\", len(data[data[\"loan_status\"]==\"FullyPaid\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Down Dampling\n",
    "Train1 = data.where(data[\"loan_status\"] == \"ChargedOff\").dropna()\n",
    "Train2 = data.where(data[\"loan_status\"] == \"FullyPaid\").dropna()\n",
    "Train3 = Train2.sample(n=len(Train1), random_state=0)\n",
    "TrainData = pd.concat([Train1, Train3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData.shape\n",
    "data = TrainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      id    loan_amnt     term  interest_rate grade employment_length  \\\n",
       "1    1.0  1183.266999  5 years      10.286776    B1          10 years   \n",
       "7    7.0  2147.822844  5 years      23.738449    A3          10 years   \n",
       "9    9.0   701.824350  3 years      11.321683    B4           0 years   \n",
       "12  12.0  1244.631171  3 years      18.932798    D3           0 years   \n",
       "24  24.0  2278.044730  5 years      13.757983    C5            1 year   \n",
       "\n",
       "               purpose  credit_score application_type loan_status  \n",
       "1          credit_card    697.706701       Individual  ChargedOff  \n",
       "7   debt_consolidation    656.789397       Individual  ChargedOff  \n",
       "9          credit_card    656.609116       Individual  ChargedOff  \n",
       "12  debt_consolidation    656.933143       Individual  ChargedOff  \n",
       "24         credit_card    719.038856       Individual  ChargedOff  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>loan_amnt</th>\n      <th>term</th>\n      <th>interest_rate</th>\n      <th>grade</th>\n      <th>employment_length</th>\n      <th>purpose</th>\n      <th>credit_score</th>\n      <th>application_type</th>\n      <th>loan_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>1183.266999</td>\n      <td>5 years</td>\n      <td>10.286776</td>\n      <td>B1</td>\n      <td>10 years</td>\n      <td>credit_card</td>\n      <td>697.706701</td>\n      <td>Individual</td>\n      <td>ChargedOff</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7.0</td>\n      <td>2147.822844</td>\n      <td>5 years</td>\n      <td>23.738449</td>\n      <td>A3</td>\n      <td>10 years</td>\n      <td>debt_consolidation</td>\n      <td>656.789397</td>\n      <td>Individual</td>\n      <td>ChargedOff</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9.0</td>\n      <td>701.824350</td>\n      <td>3 years</td>\n      <td>11.321683</td>\n      <td>B4</td>\n      <td>0 years</td>\n      <td>credit_card</td>\n      <td>656.609116</td>\n      <td>Individual</td>\n      <td>ChargedOff</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12.0</td>\n      <td>1244.631171</td>\n      <td>3 years</td>\n      <td>18.932798</td>\n      <td>D3</td>\n      <td>0 years</td>\n      <td>debt_consolidation</td>\n      <td>656.933143</td>\n      <td>Individual</td>\n      <td>ChargedOff</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>24.0</td>\n      <td>2278.044730</td>\n      <td>5 years</td>\n      <td>13.757983</td>\n      <td>C5</td>\n      <td>1 year</td>\n      <td>credit_card</td>\n      <td>719.038856</td>\n      <td>Individual</td>\n      <td>ChargedOff</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 258
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter3\n",
    "# def pre_process(input_data):\n",
    "# データ前処理\n",
    "# One-Hotエンコーディング\n",
    "# pre_X = input_data.drop([\"loan_status\", \"id\"], axis=1).replace({\n",
    "pre_X = data.drop([\"loan_status\", \"purpose\"], axis=1).replace({\n",
    "    \"A1\": 1, \"A2\": 2, \"A3\": 3, \"A4\": 4, \"A5\": 5,\n",
    "    \"B1\": 6, \"B2\": 7, \"B3\": 8, \"B4\": 9, \"B5\": 10,\n",
    "    \"C1\": 11, \"C2\": 12, \"C3\": 13, \"C4\": 14, \"C5\": 15,\n",
    "    \"D1\": 16, \"D2\": 17, \"D3\": 18, \"D4\": 19, \"D5\": 20,\n",
    "    \"E1\": 21, \"E2\": 22, \"E3\": 23, \"E4\": 24, \"E5\": 25,\n",
    "    \"F1\": 26, \"F2\": 27, \"F3\": 28, \"F4\": 29, \"F5\": 30,\n",
    "    \"0 year\": 0, \"0 years\": 0, \"1 years\": 1, \"1 year\": 1, \"2 years\": 2, \"3 years\": 3, \"4 years\": 4, \"5 years\": 5,\n",
    "    \"6 years\": 6, \"7 years\": 7, \"8 years\": 8, \"9 years\": 9, \"10 years\": 10,\n",
    "    \"Individual\": 1, \"Joint App\": 0,\n",
    "}).astype({\n",
    "    \"term\": \"int8\",\n",
    "    \"grade\": \"int8\",\n",
    "    \"employment_length\": \"int8\",\n",
    "    \"application_type\": \"int8\",\n",
    "})\n",
    "pre_y = data[\"loan_status\"]\n",
    "X = pd.get_dummies(pre_X)\n",
    "y = pre_y.replace({\"ChargedOff\": 1, \"FullyPaid\": 0})\n",
    "# pre_X_train, pre_X_test = train_test_split(X, test_size=0.1, shuffle=False)\n",
    "# y_train, y_test = train_test_split(y, test_size=0.1, shuffle=False)\n",
    "\n",
    "# X_train = X\n",
    "# X_test = X\n",
    "y_train = y\n",
    "y_test = y\n",
    "\n",
    "# 加工が終わった時点でCSVに出すと、ほかのモデルでの使いまわしがきく。\n",
    "# # Min-Maxスケーリング\n",
    "# X_train = ((pre_X_train - pre_X_train.min()) / (pre_X_train.max() - pre_X_train.min()))\n",
    "pre_X_train = ((X - X.min()) / (X.max() - X.min()))\n",
    "# X_train = pre_X_train\n",
    "# # Min-Maxスケーリング\n",
    "# X_test = ((pre_X_test - pre_X_test.min()) / (pre_X_test.max() - pre_X_test.min()))\n",
    "pre_X_test = ((X - X.min()) / (X.max() - X.min()))\n",
    "# X_test = pre_X_test\n",
    "    # return X_train, X_test, y_train, y_test\n",
    "# X_train, X_test, y_train, y_test = pre_process(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          id  loan_amnt  term  interest_rate     grade  employment_length  \\\n",
       "1   0.000000   0.242699   1.0       0.206435  0.172414                1.0   \n",
       "7   0.000025   0.516423   1.0       0.814364  0.068966                1.0   \n",
       "9   0.000033   0.106075   0.0       0.253206  0.275862                0.0   \n",
       "12  0.000045   0.260113   0.0       0.597179  0.586207                0.0   \n",
       "24  0.000095   0.553377   1.0       0.363311  0.482759                0.1   \n",
       "\n",
       "    credit_score  application_type  \n",
       "1       0.278140               1.0  \n",
       "7       0.008612               1.0  \n",
       "9       0.007425               1.0  \n",
       "12      0.009559               1.0  \n",
       "24      0.418657               1.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>loan_amnt</th>\n      <th>term</th>\n      <th>interest_rate</th>\n      <th>grade</th>\n      <th>employment_length</th>\n      <th>credit_score</th>\n      <th>application_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.242699</td>\n      <td>1.0</td>\n      <td>0.206435</td>\n      <td>0.172414</td>\n      <td>1.0</td>\n      <td>0.278140</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.000025</td>\n      <td>0.516423</td>\n      <td>1.0</td>\n      <td>0.814364</td>\n      <td>0.068966</td>\n      <td>1.0</td>\n      <td>0.008612</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.000033</td>\n      <td>0.106075</td>\n      <td>0.0</td>\n      <td>0.253206</td>\n      <td>0.275862</td>\n      <td>0.0</td>\n      <td>0.007425</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.000045</td>\n      <td>0.260113</td>\n      <td>0.0</td>\n      <td>0.597179</td>\n      <td>0.586207</td>\n      <td>0.0</td>\n      <td>0.009559</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.000095</td>\n      <td>0.553377</td>\n      <td>1.0</td>\n      <td>0.363311</td>\n      <td>0.482759</td>\n      <td>0.1</td>\n      <td>0.418657</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 260
    }
   ],
   "source": [
    "pre_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_X_train = pre_X_train.astype(\"float32\")\n",
    "X_train = pre_X_train.astype({\n",
    "    \"term\": \"int8\",\n",
    "    \"grade\": \"int8\",\n",
    "    \"employment_length\": \"int8\",\n",
    "    \"application_type\": \"int8\",\n",
    "    # \"purpose_car\": \"int8\",\n",
    "    # \"purpose_credit_card\": \"int8\",\n",
    "    # \"purpose_debt_consolidation\": \"int8\",\n",
    "    # \"purpose_home_improvement\": \"int8\",\n",
    "    # \"purpose_house\": \"int8\",\n",
    "    # \"purpose_major_purchase\": \"int8\",\n",
    "    # \"purpose_medical\": \"int8\",\n",
    "    # \"purpose_other\": \"int8\",\n",
    "    # \"purpose_small_business\": \"int8\",\n",
    "})\n",
    "X_test = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "訓練データの特徴量 (84712, 8)\n",
      "訓練データのターゲット (84712,)\n"
     ]
    }
   ],
   "source": [
    "print(\"訓練データの特徴量\", X_train.shape)\n",
    "print(\"訓練データのターゲット\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras  # Keras\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.metrics import binary_accuracy, Accuracy\n",
    "import optuna\n",
    "\n",
    "\n",
    "def create_model(units1, units2, lr):\n",
    "    keras.backend.clear_session()\n",
    "    # Keras以外を利用するのも一つの手段。\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Dense(units=units1, input_dim = 8, activation=tf.nn.relu)) \n",
    "    # model.add(Dropout(0.5))\n",
    "    model.add(keras.layers.BatchNormalization())  # バッチ正規化層\n",
    "    model.add(Dense(units=units2, activation=tf.nn.relu)) \n",
    "    # model.add(Dropout(0.5))\n",
    "    model.add(keras.layers.BatchNormalization())  # バッチ正規化層\n",
    "    model.add(Dense(units=2, activation=\"softmax\"))  # 出力層（活性化関数はソフトマックス関数）\n",
    "    model.compile(optimizer = keras.optimizers.SGD(lr=lr),\n",
    "           loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=\"accuracy\")\n",
    "         #    f1scoreにするのがよい\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    keras.backend.clear_session()\n",
    "    # 調整したいハイパーパラメータの設定\n",
    "    # n_layer = trial.suggest_int('n_layer', 1, 2) # 追加する層を1-3から選ぶ\n",
    "    units1 = int(trial.suggest_discrete_uniform('units1', 100, 300, 1)) # ユニット数\n",
    "    units2 = int(trial.suggest_discrete_uniform('units2', 100, 300, 1)) # ユニット数\n",
    "    epochs = int(trial.suggest_discrete_uniform('epochs', 100, 300, 10)) # ユニット数\n",
    "    lr = trial.suggest_float('lr', 0.01, 0.1,step=0.01) # 学習率\n",
    "\n",
    "    model = create_model(units1, units2, lr)\n",
    "\n",
    "        # (5)学習を実行してください\n",
    "    es_cb = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 3)\n",
    "    history = model.fit(x = X_train,\n",
    "        y = y_train,\n",
    "        batch_size = 256, # バッチサイズ\n",
    "        # epochs = 100, # エポック数\n",
    "        epochs = epochs, # エポック数\n",
    "        validation_split = 0.2, # 検証データの割合\n",
    "        # callbacks = [es_cb], # 早期終了の設定\n",
    "        verbose = 0) # 進捗の確認を行うか（0:行わない, 1:行う）\n",
    "\n",
    "    # return history.history[\"loss\"][-1]\n",
    "    # return history.history[\"val_loss\"][-1]\n",
    "    # return 1 - history.history[\"accuracy\"][-1]\n",
    "    return 1 - history.history[\"val_accuracy\"][-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[I 2020-10-18 17:51:58,024] Trial 0 finished with value: 0.7402467131614685 and parameters: {'units1': 275.0, 'units2': 190.0, 'epochs': 110.0, 'lr': 0.06999999999999999}. Best is trial 0 with value: 0.7402467131614685.\n",
      "[I 2020-10-18 17:53:18,095] Trial 1 finished with value: 0.6169509589672089 and parameters: {'units1': 204.0, 'units2': 259.0, 'epochs': 200.0, 'lr': 0.09999999999999999}. Best is trial 1 with value: 0.6169509589672089.\n",
      "[I 2020-10-18 17:55:00,071] Trial 2 finished with value: 0.6220858097076416 and parameters: {'units1': 184.0, 'units2': 297.0, 'epochs': 250.0, 'lr': 0.04}. Best is trial 1 with value: 0.6169509589672089.\n",
      "[I 2020-10-18 17:56:49,285] Trial 3 finished with value: 0.7036534249782562 and parameters: {'units1': 121.0, 'units2': 189.0, 'epochs': 270.0, 'lr': 0.03}. Best is trial 1 with value: 0.6169509589672089.\n",
      "[I 2020-10-18 17:57:51,137] Trial 4 finished with value: 0.7333412170410156 and parameters: {'units1': 271.0, 'units2': 178.0, 'epochs': 150.0, 'lr': 0.09}. Best is trial 1 with value: 0.6169509589672089.\n",
      "[I 2020-10-18 17:58:36,715] Trial 5 finished with value: 0.74455526471138 and parameters: {'units1': 286.0, 'units2': 109.0, 'epochs': 110.0, 'lr': 0.03}. Best is trial 1 with value: 0.6169509589672089.\n",
      "[I 2020-10-18 17:59:21,328] Trial 6 finished with value: 0.7309213280677795 and parameters: {'units1': 162.0, 'units2': 164.0, 'epochs': 110.0, 'lr': 0.04}. Best is trial 1 with value: 0.6169509589672089.\n",
      "[I 2020-10-18 18:00:10,826] Trial 7 finished with value: 0.7218320369720459 and parameters: {'units1': 216.0, 'units2': 197.0, 'epochs': 120.0, 'lr': 0.04}. Best is trial 1 with value: 0.6169509589672089.\n",
      "[I 2020-10-18 18:01:57,672] Trial 8 finished with value: 0.7247830927371979 and parameters: {'units1': 290.0, 'units2': 102.0, 'epochs': 260.0, 'lr': 0.05}. Best is trial 1 with value: 0.6169509589672089.\n",
      "[I 2020-10-18 18:02:43,621] Trial 9 finished with value: 0.7455586493015289 and parameters: {'units1': 210.0, 'units2': 114.0, 'epochs': 110.0, 'lr': 0.08}. Best is trial 1 with value: 0.6169509589672089.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epochs : 200.0\n",
      "lr : 0.09999999999999999\n",
      "units1 : 204.0\n",
      "units2 : 259.0\n"
     ]
    }
   ],
   "source": [
    "sorted_best_params = sorted(study.best_params.items(), key=lambda x : x[0])\n",
    "best_param = dict()\n",
    "for i, k in sorted_best_params:\n",
    "    print(i + ' : ' + str(k))\n",
    "    best_param[i] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6169509589672089"
      ]
     },
     "metadata": {},
     "execution_count": 270
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras以外を利用するのも一つの手段。\n",
    "keras.backend.clear_session()\n",
    "# Keras以外を利用するのも一つの手段。\n",
    "model = keras.models.Sequential()\n",
    "model.add(Dense(units=best_param[\"units1\"], input_dim = 8, activation=tf.nn.relu)) \n",
    "# model.add(Dropout(0.5))\n",
    "model.add(keras.layers.BatchNormalization())  # バッチ正規化層\n",
    "model.add(Dense(units=best_param[\"units2\"], activation=tf.nn.relu)) \n",
    "# model.add(Dropout(0.5))\n",
    "model.add(keras.layers.BatchNormalization())  # バッチ正規化層\n",
    "model.add(Dense(units=2, activation=\"softmax\"))  # 出力層（活性化関数はソフトマックス関数）\n",
    "model.compile(optimizer = keras.optimizers.SGD(lr=best_param[\"lr\"]),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoge = [\"mean_squared_error\",\"mean_absolute_error\",\"mean_absolute_percentage_error\",\"mean_squared_logarithmic_error\",\"squared_hinge\",\"hinge\",\"categorical_hinge\",\"sparse_categorical_crossentropy\",\"kullback_leibler_divergence\",\"poisson\"]\n",
    "\n",
    "# for loss in hoge:\n",
    "#     # Keras以外を利用するのも一つの手段。\n",
    "#     try:\n",
    "#         keras.backend.clear_session()\n",
    "#         model = keras.models.Sequential()\n",
    "#         model.add(Dense(units=10, activation=tf.nn.relu)) \n",
    "#         model.add(keras.layers.BatchNormalization())  # バッチ正規化層\n",
    "#         model.add(Dense(units=10, activation=tf.nn.relu)) \n",
    "#         model.add(keras.layers.BatchNormalization())  # バッチ正規化層\n",
    "#         model.add(Dense(units=2, activation=tf.nn.sigmoid))  # 出力層（活性化関数はソフトマックス関数）\n",
    "#         model.compile(optimizer = keras.optimizers.SGD(lr=best_param[\"lr\"]),\n",
    "#                 loss=loss,\n",
    "#                 metrics=\"accuracy\")\n",
    "#         model.fit(x=X_train,\n",
    "#         y=y_train,\n",
    "#         batch_size=256,  # バッチサイズ\n",
    "#         epochs=int(10),  # エポック数\n",
    "#         validation_split=0.2,  # 検証データの割合\n",
    "#         verbose=0)  # 進捗の確認を行うか（0:行わない, 1:行う）\n",
    "#     except:\n",
    "#         print(\"unknown loss:\" + loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "338 - val_accuracy: 0.2968\n",
      "Epoch 63/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.6009 - accuracy: 0.6799 - val_loss: 0.8807 - val_accuracy: 0.3093\n",
      "Epoch 64/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.6009 - accuracy: 0.6805 - val_loss: 0.9155 - val_accuracy: 0.2962\n",
      "Epoch 65/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.6002 - accuracy: 0.6806 - val_loss: 0.9011 - val_accuracy: 0.2667\n",
      "Epoch 66/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.6006 - accuracy: 0.6815 - val_loss: 0.9133 - val_accuracy: 0.2485\n",
      "Epoch 67/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5998 - accuracy: 0.6791 - val_loss: 0.8933 - val_accuracy: 0.2924\n",
      "Epoch 68/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.6003 - accuracy: 0.6801 - val_loss: 0.9230 - val_accuracy: 0.2751\n",
      "Epoch 69/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.6008 - accuracy: 0.6793 - val_loss: 0.9181 - val_accuracy: 0.2492\n",
      "Epoch 70/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.6006 - accuracy: 0.6796 - val_loss: 0.9137 - val_accuracy: 0.2579\n",
      "Epoch 71/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5996 - accuracy: 0.6799 - val_loss: 0.9127 - val_accuracy: 0.2582\n",
      "Epoch 72/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5999 - accuracy: 0.6800 - val_loss: 0.8799 - val_accuracy: 0.3516\n",
      "Epoch 73/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5994 - accuracy: 0.6806 - val_loss: 0.9047 - val_accuracy: 0.3452\n",
      "Epoch 74/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5997 - accuracy: 0.6805 - val_loss: 0.8909 - val_accuracy: 0.2675\n",
      "Epoch 75/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.6003 - accuracy: 0.6802 - val_loss: 0.8814 - val_accuracy: 0.2803\n",
      "Epoch 76/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.6004 - accuracy: 0.6807 - val_loss: 0.8894 - val_accuracy: 0.2579\n",
      "Epoch 77/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5986 - accuracy: 0.6799 - val_loss: 0.8923 - val_accuracy: 0.3158\n",
      "Epoch 78/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5999 - accuracy: 0.6806 - val_loss: 0.8835 - val_accuracy: 0.2490\n",
      "Epoch 79/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5995 - accuracy: 0.6817 - val_loss: 0.8961 - val_accuracy: 0.2622\n",
      "Epoch 80/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5990 - accuracy: 0.6799 - val_loss: 0.8873 - val_accuracy: 0.2736\n",
      "Epoch 81/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5989 - accuracy: 0.6815 - val_loss: 0.8791 - val_accuracy: 0.3130\n",
      "Epoch 82/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5992 - accuracy: 0.6788 - val_loss: 0.8963 - val_accuracy: 0.2877\n",
      "Epoch 83/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5990 - accuracy: 0.6801 - val_loss: 0.9120 - val_accuracy: 0.2831\n",
      "Epoch 84/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5992 - accuracy: 0.6814 - val_loss: 0.8787 - val_accuracy: 0.2814\n",
      "Epoch 85/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5987 - accuracy: 0.6816 - val_loss: 0.9213 - val_accuracy: 0.2854\n",
      "Epoch 86/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5985 - accuracy: 0.6814 - val_loss: 0.9294 - val_accuracy: 0.2784\n",
      "Epoch 87/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.6822 - val_loss: 0.8553 - val_accuracy: 0.3529\n",
      "Epoch 88/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5984 - accuracy: 0.6807 - val_loss: 0.9089 - val_accuracy: 0.2770\n",
      "Epoch 89/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.6802 - val_loss: 0.9137 - val_accuracy: 0.2605\n",
      "Epoch 90/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5983 - accuracy: 0.6808 - val_loss: 0.8763 - val_accuracy: 0.3613\n",
      "Epoch 91/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5977 - accuracy: 0.6823 - val_loss: 0.9275 - val_accuracy: 0.2409\n",
      "Epoch 92/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5983 - accuracy: 0.6818 - val_loss: 0.8512 - val_accuracy: 0.3953\n",
      "Epoch 93/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5985 - accuracy: 0.6809 - val_loss: 0.8809 - val_accuracy: 0.3363\n",
      "Epoch 94/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.6816 - val_loss: 0.8850 - val_accuracy: 0.3370\n",
      "Epoch 95/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5968 - accuracy: 0.6811 - val_loss: 0.9264 - val_accuracy: 0.2592\n",
      "Epoch 96/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5978 - accuracy: 0.6817 - val_loss: 0.9082 - val_accuracy: 0.2442\n",
      "Epoch 97/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5970 - accuracy: 0.6816 - val_loss: 0.9199 - val_accuracy: 0.2848\n",
      "Epoch 98/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5976 - accuracy: 0.6820 - val_loss: 0.8919 - val_accuracy: 0.2919\n",
      "Epoch 99/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5979 - accuracy: 0.6808 - val_loss: 0.8753 - val_accuracy: 0.3020\n",
      "Epoch 100/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5983 - accuracy: 0.6824 - val_loss: 0.8780 - val_accuracy: 0.3174\n",
      "Epoch 101/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5970 - accuracy: 0.6814 - val_loss: 0.9187 - val_accuracy: 0.2407\n",
      "Epoch 102/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5969 - accuracy: 0.6823 - val_loss: 0.9147 - val_accuracy: 0.2703\n",
      "Epoch 103/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5974 - accuracy: 0.6816 - val_loss: 0.8658 - val_accuracy: 0.3013\n",
      "Epoch 104/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5975 - accuracy: 0.6807 - val_loss: 0.8593 - val_accuracy: 0.3208\n",
      "Epoch 105/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5975 - accuracy: 0.6818 - val_loss: 0.8942 - val_accuracy: 0.3178\n",
      "Epoch 106/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5977 - accuracy: 0.6829 - val_loss: 0.8604 - val_accuracy: 0.3604\n",
      "Epoch 107/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5965 - accuracy: 0.6822 - val_loss: 0.9158 - val_accuracy: 0.2468\n",
      "Epoch 108/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5971 - accuracy: 0.6812 - val_loss: 0.8944 - val_accuracy: 0.3648\n",
      "Epoch 109/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5968 - accuracy: 0.6823 - val_loss: 0.8748 - val_accuracy: 0.3904\n",
      "Epoch 110/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5969 - accuracy: 0.6825 - val_loss: 0.9293 - val_accuracy: 0.2479\n",
      "Epoch 111/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5964 - accuracy: 0.6816 - val_loss: 0.8669 - val_accuracy: 0.3704\n",
      "Epoch 112/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5964 - accuracy: 0.6816 - val_loss: 0.8750 - val_accuracy: 0.3806\n",
      "Epoch 113/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5967 - accuracy: 0.6809 - val_loss: 0.9180 - val_accuracy: 0.2834\n",
      "Epoch 114/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5962 - accuracy: 0.6824 - val_loss: 0.9036 - val_accuracy: 0.2808\n",
      "Epoch 115/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5963 - accuracy: 0.6822 - val_loss: 0.9049 - val_accuracy: 0.2738\n",
      "Epoch 116/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5964 - accuracy: 0.6823 - val_loss: 0.8663 - val_accuracy: 0.3285\n",
      "Epoch 117/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5966 - accuracy: 0.6822 - val_loss: 0.8851 - val_accuracy: 0.2642\n",
      "Epoch 118/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5958 - accuracy: 0.6824 - val_loss: 0.9059 - val_accuracy: 0.2452\n",
      "Epoch 119/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5963 - accuracy: 0.6811 - val_loss: 0.8929 - val_accuracy: 0.3058\n",
      "Epoch 120/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5960 - accuracy: 0.6828 - val_loss: 0.9142 - val_accuracy: 0.2802\n",
      "Epoch 121/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5953 - accuracy: 0.6841 - val_loss: 0.8790 - val_accuracy: 0.3458\n",
      "Epoch 122/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.6819 - val_loss: 0.8858 - val_accuracy: 0.3305\n",
      "Epoch 123/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5956 - accuracy: 0.6832 - val_loss: 0.8845 - val_accuracy: 0.3507\n",
      "Epoch 124/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5953 - accuracy: 0.6824 - val_loss: 0.8999 - val_accuracy: 0.2702\n",
      "Epoch 125/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5963 - accuracy: 0.6832 - val_loss: 0.8698 - val_accuracy: 0.3412\n",
      "Epoch 126/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5955 - accuracy: 0.6826 - val_loss: 0.9042 - val_accuracy: 0.2972\n",
      "Epoch 127/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5956 - accuracy: 0.6834 - val_loss: 0.8716 - val_accuracy: 0.2953\n",
      "Epoch 128/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5953 - accuracy: 0.6836 - val_loss: 0.8942 - val_accuracy: 0.3021\n",
      "Epoch 129/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5954 - accuracy: 0.6826 - val_loss: 0.8992 - val_accuracy: 0.3112\n",
      "Epoch 130/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5948 - accuracy: 0.6829 - val_loss: 0.9055 - val_accuracy: 0.2919\n",
      "Epoch 131/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5947 - accuracy: 0.6824 - val_loss: 0.8680 - val_accuracy: 0.3306\n",
      "Epoch 132/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5950 - accuracy: 0.6830 - val_loss: 0.8636 - val_accuracy: 0.3432\n",
      "Epoch 133/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5948 - accuracy: 0.6830 - val_loss: 0.9019 - val_accuracy: 0.3074\n",
      "Epoch 134/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5950 - accuracy: 0.6828 - val_loss: 0.9063 - val_accuracy: 0.2741\n",
      "Epoch 135/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.6837 - val_loss: 0.8427 - val_accuracy: 0.3733\n",
      "Epoch 136/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5951 - accuracy: 0.6825 - val_loss: 0.8871 - val_accuracy: 0.3410\n",
      "Epoch 137/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5946 - accuracy: 0.6835 - val_loss: 0.9217 - val_accuracy: 0.2595\n",
      "Epoch 138/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5948 - accuracy: 0.6840 - val_loss: 0.9008 - val_accuracy: 0.3202\n",
      "Epoch 139/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5949 - accuracy: 0.6836 - val_loss: 0.8776 - val_accuracy: 0.3233\n",
      "Epoch 140/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.6835 - val_loss: 0.8824 - val_accuracy: 0.2698\n",
      "Epoch 141/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5950 - accuracy: 0.6832 - val_loss: 0.8800 - val_accuracy: 0.2829\n",
      "Epoch 142/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5946 - accuracy: 0.6816 - val_loss: 0.8573 - val_accuracy: 0.3678\n",
      "Epoch 143/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5942 - accuracy: 0.6821 - val_loss: 0.8873 - val_accuracy: 0.2807\n",
      "Epoch 144/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5945 - accuracy: 0.6841 - val_loss: 0.8707 - val_accuracy: 0.3525\n",
      "Epoch 145/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.6834 - val_loss: 0.9190 - val_accuracy: 0.2877\n",
      "Epoch 146/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.6836 - val_loss: 0.9029 - val_accuracy: 0.2815\n",
      "Epoch 147/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.6832 - val_loss: 0.9029 - val_accuracy: 0.2884\n",
      "Epoch 148/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.6832 - val_loss: 0.8927 - val_accuracy: 0.3386\n",
      "Epoch 149/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5940 - accuracy: 0.6837 - val_loss: 0.8906 - val_accuracy: 0.2670\n",
      "Epoch 150/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5951 - accuracy: 0.6832 - val_loss: 0.9061 - val_accuracy: 0.2615\n",
      "Epoch 151/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5936 - accuracy: 0.6830 - val_loss: 0.8774 - val_accuracy: 0.2757\n",
      "Epoch 152/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.6842 - val_loss: 0.9091 - val_accuracy: 0.2602\n",
      "Epoch 153/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.6843 - val_loss: 0.9124 - val_accuracy: 0.2740\n",
      "Epoch 154/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5935 - accuracy: 0.6848 - val_loss: 0.8903 - val_accuracy: 0.2934\n",
      "Epoch 155/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.6849 - val_loss: 0.8807 - val_accuracy: 0.3291\n",
      "Epoch 156/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5939 - accuracy: 0.6846 - val_loss: 0.9151 - val_accuracy: 0.2949\n",
      "Epoch 157/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5935 - accuracy: 0.6838 - val_loss: 0.9021 - val_accuracy: 0.2681\n",
      "Epoch 158/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5936 - accuracy: 0.6851 - val_loss: 0.8657 - val_accuracy: 0.3384\n",
      "Epoch 159/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5934 - accuracy: 0.6840 - val_loss: 0.8973 - val_accuracy: 0.3256\n",
      "Epoch 160/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5932 - accuracy: 0.6842 - val_loss: 0.8852 - val_accuracy: 0.3964\n",
      "Epoch 161/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5928 - accuracy: 0.6846 - val_loss: 0.8552 - val_accuracy: 0.3584\n",
      "Epoch 162/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5928 - accuracy: 0.6830 - val_loss: 0.8980 - val_accuracy: 0.2910\n",
      "Epoch 163/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5932 - accuracy: 0.6836 - val_loss: 0.9184 - val_accuracy: 0.2331\n",
      "Epoch 164/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5931 - accuracy: 0.6839 - val_loss: 0.8979 - val_accuracy: 0.2595\n",
      "Epoch 165/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5931 - accuracy: 0.6842 - val_loss: 0.8753 - val_accuracy: 0.3008\n",
      "Epoch 166/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5934 - accuracy: 0.6844 - val_loss: 0.8845 - val_accuracy: 0.3143\n",
      "Epoch 167/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5927 - accuracy: 0.6844 - val_loss: 0.9200 - val_accuracy: 0.2901\n",
      "Epoch 168/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5929 - accuracy: 0.6856 - val_loss: 0.8855 - val_accuracy: 0.3144\n",
      "Epoch 169/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5926 - accuracy: 0.6841 - val_loss: 0.8819 - val_accuracy: 0.2576\n",
      "Epoch 170/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5925 - accuracy: 0.6838 - val_loss: 0.9029 - val_accuracy: 0.3246\n",
      "Epoch 171/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5927 - accuracy: 0.6848 - val_loss: 0.8941 - val_accuracy: 0.2934\n",
      "Epoch 172/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5927 - accuracy: 0.6840 - val_loss: 0.8742 - val_accuracy: 0.3669\n",
      "Epoch 173/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5922 - accuracy: 0.6855 - val_loss: 0.8747 - val_accuracy: 0.3259\n",
      "Epoch 174/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5925 - accuracy: 0.6844 - val_loss: 0.8958 - val_accuracy: 0.2800\n",
      "Epoch 175/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5922 - accuracy: 0.6837 - val_loss: 0.9074 - val_accuracy: 0.2807\n",
      "Epoch 176/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5920 - accuracy: 0.6847 - val_loss: 0.9007 - val_accuracy: 0.2863\n",
      "Epoch 177/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5921 - accuracy: 0.6842 - val_loss: 0.9037 - val_accuracy: 0.2931\n",
      "Epoch 178/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5923 - accuracy: 0.6834 - val_loss: 0.8682 - val_accuracy: 0.3496\n",
      "Epoch 179/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5926 - accuracy: 0.6843 - val_loss: 0.8787 - val_accuracy: 0.2847\n",
      "Epoch 180/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5915 - accuracy: 0.6836 - val_loss: 0.8765 - val_accuracy: 0.3213\n",
      "Epoch 181/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5914 - accuracy: 0.6848 - val_loss: 0.8650 - val_accuracy: 0.3457\n",
      "Epoch 182/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5918 - accuracy: 0.6843 - val_loss: 0.9539 - val_accuracy: 0.2399\n",
      "Epoch 183/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5915 - accuracy: 0.6851 - val_loss: 0.8961 - val_accuracy: 0.2794\n",
      "Epoch 184/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5919 - accuracy: 0.6858 - val_loss: 0.9591 - val_accuracy: 0.2540\n",
      "Epoch 185/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5912 - accuracy: 0.6859 - val_loss: 0.8885 - val_accuracy: 0.2779\n",
      "Epoch 186/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5913 - accuracy: 0.6850 - val_loss: 0.9252 - val_accuracy: 0.2624\n",
      "Epoch 187/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5918 - accuracy: 0.6838 - val_loss: 0.9146 - val_accuracy: 0.3373\n",
      "Epoch 188/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5916 - accuracy: 0.6852 - val_loss: 0.9246 - val_accuracy: 0.2688\n",
      "Epoch 189/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5914 - accuracy: 0.6846 - val_loss: 0.8957 - val_accuracy: 0.2883\n",
      "Epoch 190/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5920 - accuracy: 0.6831 - val_loss: 0.8723 - val_accuracy: 0.3511\n",
      "Epoch 191/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5917 - accuracy: 0.6848 - val_loss: 0.9238 - val_accuracy: 0.2697\n",
      "Epoch 192/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5913 - accuracy: 0.6852 - val_loss: 0.8825 - val_accuracy: 0.3120\n",
      "Epoch 193/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5911 - accuracy: 0.6861 - val_loss: 0.8763 - val_accuracy: 0.3355\n",
      "Epoch 194/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5915 - accuracy: 0.6845 - val_loss: 0.8763 - val_accuracy: 0.3531\n",
      "Epoch 195/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5909 - accuracy: 0.6845 - val_loss: 0.8798 - val_accuracy: 0.2726\n",
      "Epoch 196/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5913 - accuracy: 0.6851 - val_loss: 0.8654 - val_accuracy: 0.3686\n",
      "Epoch 197/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5915 - accuracy: 0.6856 - val_loss: 0.9306 - val_accuracy: 0.2842\n",
      "Epoch 198/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5910 - accuracy: 0.6856 - val_loss: 0.9106 - val_accuracy: 0.2624\n",
      "Epoch 199/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5905 - accuracy: 0.6838 - val_loss: 0.8736 - val_accuracy: 0.3197\n",
      "Epoch 200/200\n",
      "265/265 [==============================] - 1s 2ms/step - loss: 0.5904 - accuracy: 0.6854 - val_loss: 0.9008 - val_accuracy: 0.3901\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train,\n",
    "       y=y_train,\n",
    "       batch_size=256,  # バッチサイズ\n",
    "       epochs=int(best_param[\"epochs\"]),  # エポック数\n",
    "       validation_split=0.2,  # 検証データの割合\n",
    "       verbose=1)  # 進捗の確認を行うか（0:行わない, 1:行う）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[17093 25263]\n",
      " [ 6615 35741]]\n"
     ]
    }
   ],
   "source": [
    "# 混同行列による評価\n",
    "y_proba = model.predict(X_test)\n",
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "confmat = confusion_matrix(y_test, y_pred)\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "正解率: 0.6236896779677024\n"
     ]
    }
   ],
   "source": [
    "# 正答率による評価\n",
    "print(\"正解率:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    y  y_pred\n",
      "1   1       0\n",
      "7   1       1\n",
      "9   1       1\n",
      "12  1       1\n",
      "24  1       1\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame({'y': y_test, 'y_pred': y_pred}).head())  # 実際のクラスと分類結果を上から5つだけ表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "回帰係数:\n",
      "                Name  Coefficients\n",
      "6       credit_score     -0.198829\n",
      "0                 id     -0.010394\n",
      "5  employment_length      0.018097\n",
      "7   application_type      0.044508\n",
      "2               term      0.050185\n",
      "1          loan_amnt      0.057248\n",
      "4              grade      0.173729\n",
      "3      interest_rate      0.631489\n",
      "切片: 0.19068694\n",
      "決定係数: 0.11894131042361988\n"
     ]
    }
   ],
   "source": [
    "# 重回帰\n",
    "from sklearn import linear_model  # 線形回帰を行うためのモジュール\n",
    "# 変数の準備\n",
    "# X = data_oh.drop([\"loan_status_ChargedOff\", \"loan_status_FullyPaid\"], axis=1)  # 説明変数の設定\n",
    "# y = data_oh[\"loan_status_FullyPaid\"]  # 目的変数の設定\n",
    "\n",
    "# 学習\n",
    "lr = linear_model.LinearRegression()  # 線形回帰モデルのインスタンスを作成\n",
    "lr.fit(X_train, y_train)  # 回帰の実行\n",
    "\n",
    "# 結果の確認\n",
    "print(\"回帰係数:\")\n",
    "print(pd.DataFrame({\"Name\": X_train.columns,\n",
    "                    \"Coefficients\": lr.coef_}).sort_values(by='Coefficients'))  # 回帰係数\n",
    "print(\"切片:\", lr.intercept_)  # 切片\n",
    "print(\"決定係数:\", lr.score(X_train, y_train))  # 決定係数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          id  loan_amnt  term  interest_rate  grade  employment_length  \\\n",
       "1   0.000000   0.242699     1       0.206435      0                  1   \n",
       "7   0.000025   0.516423     1       0.814364      0                  1   \n",
       "9   0.000033   0.106075     0       0.253206      0                  0   \n",
       "12  0.000045   0.260113     0       0.597179      0                  0   \n",
       "24  0.000095   0.553377     1       0.363311      0                  0   \n",
       "\n",
       "    credit_score  application_type  \n",
       "1       0.278140                 1  \n",
       "7       0.008612                 1  \n",
       "9       0.007425                 1  \n",
       "12      0.009559                 1  \n",
       "24      0.418657                 1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>loan_amnt</th>\n      <th>term</th>\n      <th>interest_rate</th>\n      <th>grade</th>\n      <th>employment_length</th>\n      <th>credit_score</th>\n      <th>application_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.242699</td>\n      <td>1</td>\n      <td>0.206435</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.278140</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.000025</td>\n      <td>0.516423</td>\n      <td>1</td>\n      <td>0.814364</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.008612</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.000033</td>\n      <td>0.106075</td>\n      <td>0</td>\n      <td>0.253206</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.007425</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.000045</td>\n      <td>0.260113</td>\n      <td>0</td>\n      <td>0.597179</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.009559</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.000095</td>\n      <td>0.553377</td>\n      <td>1</td>\n      <td>0.363311</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.418657</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 280
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ランダムフォレスト\n",
    "# # データ前処理\n",
    "# # データ分割\n",
    "# X = data.drop([\"id\", \"term\", \"grade\", \"employment_length\", \"purpose\", \"application_type\", \"loan_status\"], axis=1)\n",
    "# y_train = data[\"loan_status\"].values\n",
    "# # # Min-Maxスケーリング\n",
    "# X = ((X - X.min()) / (X.max() - X.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    y  y_pred\n",
      "1   1       0\n",
      "7   1       1\n",
      "9   1       0\n",
      "12  1       1\n",
      "24  1       1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier  # ランダムフォレストを実行するためのクラス\n",
    "# 学習\n",
    "RFC = RandomForestClassifier(max_depth=3, random_state=1)  # ランダムフォレストのインスタンスを作成\n",
    "RFC.fit(X_train, y_train)  # ランダムフォレストの学習\n",
    "\n",
    "# 分類結果の確認\n",
    "y_pred = RFC.predict(X_train)  # 分類結果\n",
    "print(pd.DataFrame({'y': y_train, 'y_pred': y_pred}).head())  # 実際のクラスと分類結果を上から5つだけ表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "正解率: 0.6346798564548116\n"
     ]
    }
   ],
   "source": [
    "# コード例2\n",
    "# モデルの精度（正解率）の確認\n",
    "print('正解率:', RFC.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[17093 25263]\n",
      " [ 6615 35741]]\n"
     ]
    }
   ],
   "source": [
    "# 混同行列による評価\n",
    "y_proba = model.predict(X_train)\n",
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "confmat = confusion_matrix(y_train, y_pred)\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history.history[\"val_accuracy\"]\n",
    "np.savetxt(\"C:\\work\\AI\\hoge.dat\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ前処理\n",
    "data_test = pd.read_csv(\"test.csv\")\n",
    "# Chapter3\n",
    "# データ前処理\n",
    "# One-Hotエンコーディング\n",
    "# pre_X = input_data.drop([\"loan_status\", \"id\"], axis=1).replace({\n",
    "pre_X = data_test.drop([\"purpose\"], axis=1).replace({\n",
    "    \"A1\": 1, \"A2\": 2, \"A3\": 3, \"A4\": 4, \"A5\": 5,\n",
    "    \"B1\": 6, \"B2\": 7, \"B3\": 8, \"B4\": 9, \"B5\": 10,\n",
    "    \"C1\": 11, \"C2\": 12, \"C3\": 13, \"C4\": 14, \"C5\": 15,\n",
    "    \"D1\": 16, \"D2\": 17, \"D3\": 18, \"D4\": 19, \"D5\": 20,\n",
    "    \"E1\": 21, \"E2\": 22, \"E3\": 23, \"E4\": 24, \"E5\": 25,\n",
    "    \"F1\": 26, \"F2\": 27, \"F3\": 28, \"F4\": 29, \"F5\": 30,\n",
    "    \"0 year\": 0, \"0 years\": 0, \"1 years\": 1, \"1 year\": 1, \"2 years\": 2, \"3 years\": 3, \"4 years\": 4, \"5 years\": 5,\n",
    "    \"6 years\": 6, \"7 years\": 7, \"8 years\": 8, \"9 years\": 9, \"10 years\": 10,\n",
    "    \"Individual\": 1, \"Joint App\": 0,\n",
    "}).astype({\n",
    "    \"term\": \"int8\",\n",
    "    \"grade\": \"int8\",\n",
    "    \"employment_length\": \"int8\",\n",
    "    \"application_type\": \"int8\",\n",
    "})\n",
    "X = pd.get_dummies(pre_X)\n",
    "\n",
    "# 加工が終わった時点でCSVに出すと、ほかのモデルでの使いまわしがきく。\n",
    "X_test = ((X - X.min()) / (X.max() - X.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.astype(\"float32\")\n",
    "X_test = X_test.astype({\n",
    "    \"term\": \"int8\",\n",
    "    \"grade\": \"int8\",\n",
    "    \"employment_length\": \"int8\",\n",
    "    \"application_type\": \"int8\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         id  loan_amnt  term  interest_rate  grade  employment_length  \\\n",
       "0  0.000000   0.233748     0       0.338255      0                  1   \n",
       "1  0.000037   0.550417     1       0.388391      0                  1   \n",
       "2  0.000074   0.528645     0       0.117750      0                  1   \n",
       "3  0.000112   0.048324     0       0.055643      0                  0   \n",
       "4  0.000149   0.563678     0       0.271754      0                  0   \n",
       "\n",
       "   credit_score  application_type  \n",
       "0      0.170125                 1  \n",
       "1      0.081955                 1  \n",
       "2      0.306207                 1  \n",
       "3      0.484529                 1  \n",
       "4      0.274790                 1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>loan_amnt</th>\n      <th>term</th>\n      <th>interest_rate</th>\n      <th>grade</th>\n      <th>employment_length</th>\n      <th>credit_score</th>\n      <th>application_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.233748</td>\n      <td>0</td>\n      <td>0.338255</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.170125</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000037</td>\n      <td>0.550417</td>\n      <td>1</td>\n      <td>0.388391</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.081955</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000074</td>\n      <td>0.528645</td>\n      <td>0</td>\n      <td>0.117750</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.306207</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000112</td>\n      <td>0.048324</td>\n      <td>0</td>\n      <td>0.055643</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.484529</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000149</td>\n      <td>0.563678</td>\n      <td>0</td>\n      <td>0.271754</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.274790</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 293
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = model.predict(X_test)\n",
    "y_pred = np.argmax(y_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"C:\\work\\AI\\hoge.dat\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-298-48f7eb2c4bb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "type(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}