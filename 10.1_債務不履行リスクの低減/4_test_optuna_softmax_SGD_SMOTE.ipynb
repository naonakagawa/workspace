{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('base': conda)",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id    loan_amnt     term  interest_rate grade employment_length  \\\n",
       "0   0   609.296068  3 years       8.421982    A5           0 years   \n",
       "1   1  1183.266999  5 years      10.286776    B1          10 years   \n",
       "2   2   695.783256  3 years      14.723425    C2            1 year   \n",
       "3   3   738.392546  3 years      14.260708    C1           0 years   \n",
       "4   4  1642.400654  5 years      25.217452    E5          10 years   \n",
       "\n",
       "              purpose  credit_score application_type loan_status  \n",
       "0  debt_consolidation    714.061803       Individual   FullyPaid  \n",
       "1         credit_card    697.706701       Individual  ChargedOff  \n",
       "2  debt_consolidation    656.419357       Individual   FullyPaid  \n",
       "3         credit_card    657.906852       Individual   FullyPaid  \n",
       "4  debt_consolidation    662.972297       Individual   FullyPaid  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>loan_amnt</th>\n      <th>term</th>\n      <th>interest_rate</th>\n      <th>grade</th>\n      <th>employment_length</th>\n      <th>purpose</th>\n      <th>credit_score</th>\n      <th>application_type</th>\n      <th>loan_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>609.296068</td>\n      <td>3 years</td>\n      <td>8.421982</td>\n      <td>A5</td>\n      <td>0 years</td>\n      <td>debt_consolidation</td>\n      <td>714.061803</td>\n      <td>Individual</td>\n      <td>FullyPaid</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1183.266999</td>\n      <td>5 years</td>\n      <td>10.286776</td>\n      <td>B1</td>\n      <td>10 years</td>\n      <td>credit_card</td>\n      <td>697.706701</td>\n      <td>Individual</td>\n      <td>ChargedOff</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>695.783256</td>\n      <td>3 years</td>\n      <td>14.723425</td>\n      <td>C2</td>\n      <td>1 year</td>\n      <td>debt_consolidation</td>\n      <td>656.419357</td>\n      <td>Individual</td>\n      <td>FullyPaid</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>738.392546</td>\n      <td>3 years</td>\n      <td>14.260708</td>\n      <td>C1</td>\n      <td>0 years</td>\n      <td>credit_card</td>\n      <td>657.906852</td>\n      <td>Individual</td>\n      <td>FullyPaid</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1642.400654</td>\n      <td>5 years</td>\n      <td>25.217452</td>\n      <td>E5</td>\n      <td>10 years</td>\n      <td>debt_consolidation</td>\n      <td>662.972297</td>\n      <td>Individual</td>\n      <td>FullyPaid</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# Chapter1\n",
    "# NN構築試行\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score  # モデルの評価を行うための関数\n",
    "from keras import metrics\n",
    "# 学習データ読み込み\n",
    "data_X = pd.read_csv(\"train.csv\")\n",
    "data = data_X\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Chapter2\n",
    "# 学習の再現を行うために乱数シードを固定するためのコード\n",
    "import os\n",
    "import random as rn\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(0)\n",
    "rn.seed(0)\n",
    "\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph())\n",
    "K.set_session(sess)\n",
    "\n",
    "pd.set_option(\"max_columns\", None)\n",
    "# pd.set_option('max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"デフォルトした人:\", len(data[data[\"loan_status\"]==\"ChargedOff\"]))\n",
    "# print(\"デフォルトしていない人:\", len(data[data[\"loan_status\"]==\"FullyPaid\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Down Sampling\n",
    "# Train1 = data.where(data[\"loan_status\"] == \"ChargedOff\").dropna()\n",
    "# Train2 = data.where(data[\"loan_status\"] == \"FullyPaid\").dropna()\n",
    "# Train3 = Train2.sample(n=len(Train1), random_state=0)\n",
    "# TrainData = pd.concat([Train1, Train3])\n",
    "# data = TrainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id    loan_amnt     term  interest_rate grade employment_length  \\\n",
       "0   0   609.296068  3 years       8.421982    A5           0 years   \n",
       "1   1  1183.266999  5 years      10.286776    B1          10 years   \n",
       "2   2   695.783256  3 years      14.723425    C2            1 year   \n",
       "3   3   738.392546  3 years      14.260708    C1           0 years   \n",
       "4   4  1642.400654  5 years      25.217452    E5          10 years   \n",
       "\n",
       "              purpose  credit_score application_type loan_status  \n",
       "0  debt_consolidation    714.061803       Individual   FullyPaid  \n",
       "1         credit_card    697.706701       Individual  ChargedOff  \n",
       "2  debt_consolidation    656.419357       Individual   FullyPaid  \n",
       "3         credit_card    657.906852       Individual   FullyPaid  \n",
       "4  debt_consolidation    662.972297       Individual   FullyPaid  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>loan_amnt</th>\n      <th>term</th>\n      <th>interest_rate</th>\n      <th>grade</th>\n      <th>employment_length</th>\n      <th>purpose</th>\n      <th>credit_score</th>\n      <th>application_type</th>\n      <th>loan_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>609.296068</td>\n      <td>3 years</td>\n      <td>8.421982</td>\n      <td>A5</td>\n      <td>0 years</td>\n      <td>debt_consolidation</td>\n      <td>714.061803</td>\n      <td>Individual</td>\n      <td>FullyPaid</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1183.266999</td>\n      <td>5 years</td>\n      <td>10.286776</td>\n      <td>B1</td>\n      <td>10 years</td>\n      <td>credit_card</td>\n      <td>697.706701</td>\n      <td>Individual</td>\n      <td>ChargedOff</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>695.783256</td>\n      <td>3 years</td>\n      <td>14.723425</td>\n      <td>C2</td>\n      <td>1 year</td>\n      <td>debt_consolidation</td>\n      <td>656.419357</td>\n      <td>Individual</td>\n      <td>FullyPaid</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>738.392546</td>\n      <td>3 years</td>\n      <td>14.260708</td>\n      <td>C1</td>\n      <td>0 years</td>\n      <td>credit_card</td>\n      <td>657.906852</td>\n      <td>Individual</td>\n      <td>FullyPaid</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1642.400654</td>\n      <td>5 years</td>\n      <td>25.217452</td>\n      <td>E5</td>\n      <td>10 years</td>\n      <td>debt_consolidation</td>\n      <td>662.972297</td>\n      <td>Individual</td>\n      <td>FullyPaid</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter3\n",
    "# def pre_process(input_data):\n",
    "# データ前処理\n",
    "# One-Hotエンコーディング\n",
    "# pre_X = input_data.drop([\"loan_status\", \"id\"], axis=1).replace({\n",
    "# IDは消す。グレード、勤続年数は順番付け。\n",
    "# 登録方式は1/0。用途は「やばそうな理由」だけフラグ立て。\n",
    "# pre_X = input_data.drop([\"loan_status\", \"id\"], axis=1).replace({\n",
    "pre_X = data.drop([\"loan_status\",\"id\"], axis=1).replace({\n",
    "    \"A1\": 1, \"A2\": 2, \"A3\": 3, \"A4\": 4, \"A5\": 5,\n",
    "    \"B1\": 6, \"B2\": 7, \"B3\": 8, \"B4\": 9, \"B5\": 10,\n",
    "    \"C1\": 11, \"C2\": 12, \"C3\": 13, \"C4\": 14, \"C5\": 15,\n",
    "    \"D1\": 16, \"D2\": 17, \"D3\": 18, \"D4\": 19, \"D5\": 20,\n",
    "    \"E1\": 21, \"E2\": 22, \"E3\": 23, \"E4\": 24, \"E5\": 25,\n",
    "    \"F1\": 26, \"F2\": 27, \"F3\": 28, \"F4\": 29, \"F5\": 30,\n",
    "    \"0 year\": 0, \"0 years\": 0, \"1 years\": 1, \"1 year\": 1, \"2 years\": 2, \"3 years\": 3, \"4 years\": 4, \"5 years\": 5,\n",
    "    \"6 years\": 6, \"7 years\": 7, \"8 years\": 8, \"9 years\": 9, \"10 years\": 10,\n",
    "    \"Individual\": 1, \"Joint App\": 0,\n",
    "    \"purpose_car\": 0,\"purpose_credit_card\": 1,\"purpose_debt_consolidation\": 1,\"purpose_home_improvement\": 0,\"purpose_house\": 0,\"purpose_major_purchase\": 0,\"purpose_medical\": 0,\"purpose_other\": 0,\"purpose_small_business\": 0,\n",
    "}).astype({\n",
    "    \"term\": \"int8\",\n",
    "    \"grade\": \"int8\",\n",
    "    \"employment_length\": \"int8\",\n",
    "    \"application_type\": \"int8\",\n",
    "})\n",
    "pre_y = data[\"loan_status\"]\n",
    "X = pd.get_dummies(pre_X)\n",
    "y = pre_y.replace({\"ChargedOff\": 1, \"FullyPaid\": 0})\n",
    "# pre_X_train, pre_X_test = train_test_split(X, test_size=0.1, shuffle=False)\n",
    "# y_train, y_test = train_test_split(y, test_size=0.1, shuffle=False)\n",
    "\n",
    "# X_train = X\n",
    "# X_test = X\n",
    "y_train = y\n",
    "y_test = y\n",
    "\n",
    "# 加工が終わった時点でCSVに出すと、ほかのモデルでの使いまわしがきく。\n",
    "# # Min-Maxスケーリング\n",
    "# X_train = ((pre_X_train - pre_X_train.min()) / (pre_X_train.max() - pre_X_train.min()))\n",
    "pre_X_train = ((X - X.min()) / (X.max() - X.min()))\n",
    "# X_train = pre_X_train\n",
    "# # Min-Maxスケーリング\n",
    "# X_test = ((pre_X_test - pre_X_test.min()) / (pre_X_test.max() - pre_X_test.min()))\n",
    "pre_X_test = ((X - X.min()) / (X.max() - X.min()))\n",
    "# X_test = pre_X_test\n",
    "    # return X_train, X_test, y_train, y_test\n",
    "# X_train, X_test, y_train, y_test = pre_process(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   loan_amnt  term  interest_rate     grade  employment_length  credit_score  \\\n",
       "0   0.080922   0.0       0.121977  0.137931                0.0      0.382933   \n",
       "1   0.243609   1.0       0.205691  0.172414                1.0      0.276126   \n",
       "2   0.105436   0.0       0.404861  0.379310                0.1      0.006498   \n",
       "3   0.117513   0.0       0.384088  0.344828                0.0      0.016213   \n",
       "4   0.373746   1.0       0.875957  0.827586                1.0      0.049292   \n",
       "\n",
       "   application_type  purpose_car  purpose_credit_card  \\\n",
       "0               1.0          0.0                  0.0   \n",
       "1               1.0          0.0                  1.0   \n",
       "2               1.0          0.0                  0.0   \n",
       "3               1.0          0.0                  1.0   \n",
       "4               1.0          0.0                  0.0   \n",
       "\n",
       "   purpose_debt_consolidation  purpose_home_improvement  purpose_house  \\\n",
       "0                         1.0                       0.0            0.0   \n",
       "1                         0.0                       0.0            0.0   \n",
       "2                         1.0                       0.0            0.0   \n",
       "3                         0.0                       0.0            0.0   \n",
       "4                         1.0                       0.0            0.0   \n",
       "\n",
       "   purpose_major_purchase  purpose_medical  purpose_other  \\\n",
       "0                     0.0              0.0            0.0   \n",
       "1                     0.0              0.0            0.0   \n",
       "2                     0.0              0.0            0.0   \n",
       "3                     0.0              0.0            0.0   \n",
       "4                     0.0              0.0            0.0   \n",
       "\n",
       "   purpose_small_business  \n",
       "0                     0.0  \n",
       "1                     0.0  \n",
       "2                     0.0  \n",
       "3                     0.0  \n",
       "4                     0.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>term</th>\n      <th>interest_rate</th>\n      <th>grade</th>\n      <th>employment_length</th>\n      <th>credit_score</th>\n      <th>application_type</th>\n      <th>purpose_car</th>\n      <th>purpose_credit_card</th>\n      <th>purpose_debt_consolidation</th>\n      <th>purpose_home_improvement</th>\n      <th>purpose_house</th>\n      <th>purpose_major_purchase</th>\n      <th>purpose_medical</th>\n      <th>purpose_other</th>\n      <th>purpose_small_business</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.080922</td>\n      <td>0.0</td>\n      <td>0.121977</td>\n      <td>0.137931</td>\n      <td>0.0</td>\n      <td>0.382933</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.243609</td>\n      <td>1.0</td>\n      <td>0.205691</td>\n      <td>0.172414</td>\n      <td>1.0</td>\n      <td>0.276126</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.105436</td>\n      <td>0.0</td>\n      <td>0.404861</td>\n      <td>0.379310</td>\n      <td>0.1</td>\n      <td>0.006498</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.117513</td>\n      <td>0.0</td>\n      <td>0.384088</td>\n      <td>0.344828</td>\n      <td>0.0</td>\n      <td>0.016213</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.373746</td>\n      <td>1.0</td>\n      <td>0.875957</td>\n      <td>0.827586</td>\n      <td>1.0</td>\n      <td>0.049292</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "pre_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 借入理由を債務整理のみに限定。フラグ系をINTに変換\n",
    "pre_X_train = pre_X_train.astype(\"float32\")\n",
    "X_train = pre_X_train.drop([\"purpose_home_improvement\", \"purpose_house\", \"purpose_major_purchase\", \"purpose_medical\", \"purpose_other\", \"purpose_small_business\", \"purpose_car\",\"purpose_credit_card\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   loan_amnt  term  interest_rate     grade  employment_length  credit_score  \\\n",
       "0   0.080922   0.0       0.121977  0.137931                0.0      0.382933   \n",
       "1   0.243609   1.0       0.205691  0.172414                1.0      0.276126   \n",
       "2   0.105436   0.0       0.404861  0.379310                0.1      0.006498   \n",
       "3   0.117513   0.0       0.384088  0.344828                0.0      0.016213   \n",
       "4   0.373746   1.0       0.875957  0.827586                1.0      0.049292   \n",
       "\n",
       "   application_type  purpose_debt_consolidation  \n",
       "0               1.0                         1.0  \n",
       "1               1.0                         0.0  \n",
       "2               1.0                         1.0  \n",
       "3               1.0                         0.0  \n",
       "4               1.0                         1.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>term</th>\n      <th>interest_rate</th>\n      <th>grade</th>\n      <th>employment_length</th>\n      <th>credit_score</th>\n      <th>application_type</th>\n      <th>purpose_debt_consolidation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.080922</td>\n      <td>0.0</td>\n      <td>0.121977</td>\n      <td>0.137931</td>\n      <td>0.0</td>\n      <td>0.382933</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.243609</td>\n      <td>1.0</td>\n      <td>0.205691</td>\n      <td>0.172414</td>\n      <td>1.0</td>\n      <td>0.276126</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.105436</td>\n      <td>0.0</td>\n      <td>0.404861</td>\n      <td>0.379310</td>\n      <td>0.1</td>\n      <td>0.006498</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.117513</td>\n      <td>0.0</td>\n      <td>0.384088</td>\n      <td>0.344828</td>\n      <td>0.0</td>\n      <td>0.016213</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.373746</td>\n      <td>1.0</td>\n      <td>0.875957</td>\n      <td>0.827586</td>\n      <td>1.0</td>\n      <td>0.049292</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "訓練データの特徴量 (399588, 8)\n",
      "訓練データのターゲット (399588,)\n"
     ]
    }
   ],
   "source": [
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(sampling_strategy='auto', k_neighbors=1, n_jobs=1, random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "print(\"訓練データの特徴量\", X_res.shape)\n",
    "print(\"訓練データのターゲット\", y_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "訓練データの特徴量 (242150, 8)\n",
      "訓練データのターゲット (242150,)\n"
     ]
    }
   ],
   "source": [
    "# SMOTE加工前のデータ数\n",
    "print(\"訓練データの特徴量\", X_train.shape)\n",
    "print(\"訓練データのターゲット\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras  # Keras\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.metrics import binary_accuracy, Accuracy\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "import optuna\n",
    "\n",
    "\n",
    "def create_model(units1, units2, lr):\n",
    "    keras.backend.clear_session()\n",
    "    # Keras以外を利用するのも一つの手段。\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Dense(units=units1, activation=tf.nn.relu)) \n",
    "    # model.add(Dropout(0.5))\n",
    "    model.add(keras.layers.BatchNormalization())  # バッチ正規化層\n",
    "    model.add(Dense(units=units2, activation=tf.nn.relu)) \n",
    "    # model.add(Dropout(0.5))\n",
    "    model.add(keras.layers.BatchNormalization())  # バッチ正規化層\n",
    "    model.add(Dense(units=2, activation=tf.nn.softmax))  # 出力層（活性化関数はソフトマックス関数）\n",
    "    model.compile(optimizer = keras.optimizers.Adam(lr=0.01),\n",
    "           loss=\"sparse_categorical_crossentropy\",\n",
    "            metrics=\"accuracy\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    keras.backend.clear_session()\n",
    "    # 調整したいハイパーパラメータの設定\n",
    "    # n_layer = trial.suggest_int('n_layer', 1, 2) # 追加する層を1-3から選ぶ\n",
    "    units1 = int(trial.suggest_discrete_uniform('units1', 100, 500, 1)) # ユニット数\n",
    "    units2 = int(trial.suggest_discrete_uniform('units2', 100, 500, 1)) # ユニット数\n",
    "    lr = trial.suggest_float('lr', 0.01, 0.1,step=0.01) # 学習率\n",
    "    \n",
    "\n",
    "    model = create_model(units1, units2, lr)\n",
    "\n",
    "    es_cb = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience = 3)\n",
    "    history = model.fit(x = X_res,\n",
    "        y = y_res,\n",
    "        batch_size = 8192, # バッチサイズ\n",
    "        # epochs = 100, # エポック数\n",
    "        epochs = 200, # エポック数\n",
    "        validation_split = 0.1, # 検証データの割合\n",
    "        # callbacks = [es_cb], # 早期終了の設定\n",
    "        verbose = 1) # 進捗の確認を行うか（0:行わない, 1:行う）\n",
    "\n",
    "    # return history.history[\"loss\"][-1]\n",
    "    # return history.history[\"val_loss\"][-1]\n",
    "    # return 1 - history.history[\"accuracy\"][-1]\n",
    "    return 1 - history.history[\"val_accuracy\"][-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "===========================] - 1s 23ms/step - loss: 0.6077 - accuracy: 0.6502 - val_loss: 0.7085 - val_accuracy: 0.5374\n",
      "Epoch 64/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6079 - accuracy: 0.6499 - val_loss: 0.6927 - val_accuracy: 0.5521\n",
      "Epoch 65/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6081 - accuracy: 0.6507 - val_loss: 0.6764 - val_accuracy: 0.6041\n",
      "Epoch 66/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6084 - accuracy: 0.6492 - val_loss: 0.7104 - val_accuracy: 0.5177\n",
      "Epoch 67/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6080 - accuracy: 0.6497 - val_loss: 0.6891 - val_accuracy: 0.5642\n",
      "Epoch 68/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6083 - accuracy: 0.6493 - val_loss: 0.7195 - val_accuracy: 0.5087\n",
      "Epoch 69/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6076 - accuracy: 0.6505 - val_loss: 0.6953 - val_accuracy: 0.5341\n",
      "Epoch 70/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6077 - accuracy: 0.6506 - val_loss: 0.7002 - val_accuracy: 0.5343\n",
      "Epoch 71/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6078 - accuracy: 0.6505 - val_loss: 0.7149 - val_accuracy: 0.5211\n",
      "Epoch 72/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6074 - accuracy: 0.6506 - val_loss: 0.6920 - val_accuracy: 0.5553\n",
      "Epoch 73/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6078 - accuracy: 0.6505 - val_loss: 0.7217 - val_accuracy: 0.5188\n",
      "Epoch 74/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6079 - accuracy: 0.6504 - val_loss: 0.7043 - val_accuracy: 0.5435\n",
      "Epoch 75/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6072 - accuracy: 0.6511 - val_loss: 0.7166 - val_accuracy: 0.5120\n",
      "Epoch 76/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6078 - accuracy: 0.6508 - val_loss: 0.6964 - val_accuracy: 0.5439\n",
      "Epoch 77/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6075 - accuracy: 0.6504 - val_loss: 0.7121 - val_accuracy: 0.5282\n",
      "Epoch 78/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6075 - accuracy: 0.6504 - val_loss: 0.6882 - val_accuracy: 0.5688\n",
      "Epoch 79/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6077 - accuracy: 0.6501 - val_loss: 0.6897 - val_accuracy: 0.5650\n",
      "Epoch 80/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6072 - accuracy: 0.6514 - val_loss: 0.6996 - val_accuracy: 0.5428\n",
      "Epoch 81/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6073 - accuracy: 0.6508 - val_loss: 0.6869 - val_accuracy: 0.5608\n",
      "Epoch 82/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6076 - accuracy: 0.6506 - val_loss: 0.7027 - val_accuracy: 0.5468\n",
      "Epoch 83/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6072 - accuracy: 0.6516 - val_loss: 0.6948 - val_accuracy: 0.5512\n",
      "Epoch 84/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6070 - accuracy: 0.6514 - val_loss: 0.6941 - val_accuracy: 0.5554\n",
      "Epoch 85/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6073 - accuracy: 0.6503 - val_loss: 0.7316 - val_accuracy: 0.5005\n",
      "Epoch 86/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6076 - accuracy: 0.6509 - val_loss: 0.6714 - val_accuracy: 0.5870\n",
      "Epoch 87/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6074 - accuracy: 0.6509 - val_loss: 0.7278 - val_accuracy: 0.4976\n",
      "Epoch 88/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6068 - accuracy: 0.6512 - val_loss: 0.7051 - val_accuracy: 0.5456\n",
      "Epoch 89/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6069 - accuracy: 0.6516 - val_loss: 0.7069 - val_accuracy: 0.5146\n",
      "Epoch 90/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6070 - accuracy: 0.6510 - val_loss: 0.6945 - val_accuracy: 0.5502\n",
      "Epoch 91/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6071 - accuracy: 0.6510 - val_loss: 0.7005 - val_accuracy: 0.5397\n",
      "Epoch 92/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6075 - accuracy: 0.6508 - val_loss: 0.6971 - val_accuracy: 0.5645\n",
      "Epoch 93/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6068 - accuracy: 0.6516 - val_loss: 0.7062 - val_accuracy: 0.5297\n",
      "Epoch 94/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6065 - accuracy: 0.6522 - val_loss: 0.6924 - val_accuracy: 0.5422\n",
      "Epoch 95/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6067 - accuracy: 0.6512 - val_loss: 0.7077 - val_accuracy: 0.5474\n",
      "Epoch 96/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6077 - accuracy: 0.6502 - val_loss: 0.6902 - val_accuracy: 0.5543\n",
      "Epoch 97/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6072 - accuracy: 0.6510 - val_loss: 0.7147 - val_accuracy: 0.5001\n",
      "Epoch 98/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6067 - accuracy: 0.6511 - val_loss: 0.7197 - val_accuracy: 0.5151\n",
      "Epoch 99/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6071 - accuracy: 0.6506 - val_loss: 0.7254 - val_accuracy: 0.4855\n",
      "Epoch 100/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6063 - accuracy: 0.6516 - val_loss: 0.7214 - val_accuracy: 0.5231\n",
      "Epoch 101/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6062 - accuracy: 0.6523 - val_loss: 0.6971 - val_accuracy: 0.5503\n",
      "Epoch 102/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6063 - accuracy: 0.6526 - val_loss: 0.6907 - val_accuracy: 0.5409\n",
      "Epoch 103/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6068 - accuracy: 0.6512 - val_loss: 0.6832 - val_accuracy: 0.5606\n",
      "Epoch 104/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6070 - accuracy: 0.6511 - val_loss: 0.7348 - val_accuracy: 0.4865\n",
      "Epoch 105/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6066 - accuracy: 0.6519 - val_loss: 0.7084 - val_accuracy: 0.5162\n",
      "Epoch 106/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6067 - accuracy: 0.6516 - val_loss: 0.7218 - val_accuracy: 0.4914\n",
      "Epoch 107/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6065 - accuracy: 0.6520 - val_loss: 0.6998 - val_accuracy: 0.5468\n",
      "Epoch 108/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6063 - accuracy: 0.6526 - val_loss: 0.6886 - val_accuracy: 0.5351\n",
      "Epoch 109/200\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.6068 - accuracy: 0.6512 - val_loss: 0.6817 - val_accuracy: 0.5635\n",
      "Epoch 110/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6066 - accuracy: 0.6516 - val_loss: 0.7007 - val_accuracy: 0.5216\n",
      "Epoch 111/200\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.6066 - accuracy: 0.6515 - val_loss: 0.7098 - val_accuracy: 0.5443\n",
      "Epoch 112/200\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.6068 - accuracy: 0.6509 - val_loss: 0.6829 - val_accuracy: 0.5736\n",
      "Epoch 113/200\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.6069 - accuracy: 0.6510 - val_loss: 0.7432 - val_accuracy: 0.4828\n",
      "Epoch 114/200\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.6064 - accuracy: 0.6515 - val_loss: 0.7032 - val_accuracy: 0.5510\n",
      "Epoch 115/200\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.6063 - accuracy: 0.6520 - val_loss: 0.7013 - val_accuracy: 0.5412\n",
      "Epoch 116/200\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.6070 - accuracy: 0.6518 - val_loss: 0.6791 - val_accuracy: 0.5752\n",
      "Epoch 117/200\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.6065 - accuracy: 0.6520 - val_loss: 0.6871 - val_accuracy: 0.5469\n",
      "Epoch 118/200\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.6060 - accuracy: 0.6521 - val_loss: 0.7199 - val_accuracy: 0.5220\n",
      "Epoch 119/200\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.6064 - accuracy: 0.6521 - val_loss: 0.7254 - val_accuracy: 0.4982\n",
      "Epoch 120/200\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.6060 - accuracy: 0.6524 - val_loss: 0.6935 - val_accuracy: 0.5448\n",
      "Epoch 121/200\n",
      "44/44 [==============================] - 1s 27ms/step - loss: 0.6065 - accuracy: 0.6513 - val_loss: 0.6985 - val_accuracy: 0.5353\n",
      "Epoch 122/200\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.6063 - accuracy: 0.6519 - val_loss: 0.7162 - val_accuracy: 0.5115\n",
      "Epoch 123/200\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.6065 - accuracy: 0.6520 - val_loss: 0.7038 - val_accuracy: 0.5405\n",
      "Epoch 124/200\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.6058 - accuracy: 0.6524 - val_loss: 0.7051 - val_accuracy: 0.5323\n",
      "Epoch 125/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6065 - accuracy: 0.6521 - val_loss: 0.6973 - val_accuracy: 0.5546\n",
      "Epoch 126/200\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.6062 - accuracy: 0.6519 - val_loss: 0.6849 - val_accuracy: 0.5643\n",
      "Epoch 127/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6063 - accuracy: 0.6515 - val_loss: 0.7098 - val_accuracy: 0.5252\n",
      "Epoch 128/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6066 - accuracy: 0.6518 - val_loss: 0.6825 - val_accuracy: 0.5889\n",
      "Epoch 129/200\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.6058 - accuracy: 0.6524 - val_loss: 0.7140 - val_accuracy: 0.5099\n",
      "Epoch 130/200\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.6059 - accuracy: 0.6531 - val_loss: 0.6762 - val_accuracy: 0.6067\n",
      "Epoch 131/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6065 - accuracy: 0.6515 - val_loss: 0.7171 - val_accuracy: 0.5168\n",
      "Epoch 132/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6064 - accuracy: 0.6516 - val_loss: 0.7336 - val_accuracy: 0.4997\n",
      "Epoch 133/200\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.6069 - accuracy: 0.6509 - val_loss: 0.7074 - val_accuracy: 0.5374\n",
      "Epoch 134/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6057 - accuracy: 0.6527 - val_loss: 0.7148 - val_accuracy: 0.5066\n",
      "Epoch 135/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6060 - accuracy: 0.6519 - val_loss: 0.6898 - val_accuracy: 0.5494\n",
      "Epoch 136/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6063 - accuracy: 0.6520 - val_loss: 0.7308 - val_accuracy: 0.4988\n",
      "Epoch 137/200\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.6060 - accuracy: 0.6524 - val_loss: 0.7511 - val_accuracy: 0.4621\n",
      "Epoch 138/200\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.6060 - accuracy: 0.6520 - val_loss: 0.7175 - val_accuracy: 0.5066\n",
      "Epoch 139/200\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.6060 - accuracy: 0.6525 - val_loss: 0.6760 - val_accuracy: 0.5907\n",
      "Epoch 140/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6059 - accuracy: 0.6522 - val_loss: 0.7152 - val_accuracy: 0.5054\n",
      "Epoch 141/200\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.6063 - accuracy: 0.6514 - val_loss: 0.6866 - val_accuracy: 0.5696\n",
      "Epoch 142/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6060 - accuracy: 0.6521 - val_loss: 0.7030 - val_accuracy: 0.5387\n",
      "Epoch 143/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6057 - accuracy: 0.6529 - val_loss: 0.6987 - val_accuracy: 0.5447\n",
      "Epoch 144/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6055 - accuracy: 0.6529 - val_loss: 0.7236 - val_accuracy: 0.4976\n",
      "Epoch 145/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6057 - accuracy: 0.6526 - val_loss: 0.6542 - val_accuracy: 0.5895\n",
      "Epoch 146/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6064 - accuracy: 0.6518 - val_loss: 0.7490 - val_accuracy: 0.4522\n",
      "Epoch 147/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6063 - accuracy: 0.6515 - val_loss: 0.7241 - val_accuracy: 0.4888\n",
      "Epoch 148/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6055 - accuracy: 0.6529 - val_loss: 0.7579 - val_accuracy: 0.4425\n",
      "Epoch 149/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6063 - accuracy: 0.6521 - val_loss: 0.7114 - val_accuracy: 0.5352\n",
      "Epoch 150/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6057 - accuracy: 0.6526 - val_loss: 0.6972 - val_accuracy: 0.5588\n",
      "Epoch 151/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6060 - accuracy: 0.6522 - val_loss: 0.6844 - val_accuracy: 0.5738\n",
      "Epoch 152/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6058 - accuracy: 0.6529 - val_loss: 0.7035 - val_accuracy: 0.5531\n",
      "Epoch 153/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6057 - accuracy: 0.6525 - val_loss: 0.6900 - val_accuracy: 0.5707\n",
      "Epoch 154/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6061 - accuracy: 0.6520 - val_loss: 0.6982 - val_accuracy: 0.5416\n",
      "Epoch 155/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6064 - accuracy: 0.6510 - val_loss: 0.7162 - val_accuracy: 0.5149\n",
      "Epoch 156/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6053 - accuracy: 0.6530 - val_loss: 0.7137 - val_accuracy: 0.5268\n",
      "Epoch 157/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6061 - accuracy: 0.6521 - val_loss: 0.6861 - val_accuracy: 0.5648\n",
      "Epoch 158/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6053 - accuracy: 0.6529 - val_loss: 0.6545 - val_accuracy: 0.6231\n",
      "Epoch 159/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6067 - accuracy: 0.6514 - val_loss: 0.7370 - val_accuracy: 0.4849\n",
      "Epoch 160/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6052 - accuracy: 0.6532 - val_loss: 0.6968 - val_accuracy: 0.5413\n",
      "Epoch 161/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6054 - accuracy: 0.6531 - val_loss: 0.7243 - val_accuracy: 0.4828\n",
      "Epoch 162/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6055 - accuracy: 0.6529 - val_loss: 0.7024 - val_accuracy: 0.5413\n",
      "Epoch 163/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6066 - accuracy: 0.6514 - val_loss: 0.7542 - val_accuracy: 0.4760\n",
      "Epoch 164/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6063 - accuracy: 0.6515 - val_loss: 0.7112 - val_accuracy: 0.5162\n",
      "Epoch 165/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6053 - accuracy: 0.6533 - val_loss: 0.7155 - val_accuracy: 0.5149\n",
      "Epoch 166/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6058 - accuracy: 0.6525 - val_loss: 0.7248 - val_accuracy: 0.5139\n",
      "Epoch 167/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6056 - accuracy: 0.6524 - val_loss: 0.7207 - val_accuracy: 0.5092\n",
      "Epoch 168/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6049 - accuracy: 0.6535 - val_loss: 0.7149 - val_accuracy: 0.5185\n",
      "Epoch 169/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6052 - accuracy: 0.6533 - val_loss: 0.7030 - val_accuracy: 0.5247\n",
      "Epoch 170/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6051 - accuracy: 0.6539 - val_loss: 0.7057 - val_accuracy: 0.5370\n",
      "Epoch 171/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6057 - accuracy: 0.6522 - val_loss: 0.7087 - val_accuracy: 0.5495\n",
      "Epoch 172/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6055 - accuracy: 0.6526 - val_loss: 0.7174 - val_accuracy: 0.5237\n",
      "Epoch 173/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6051 - accuracy: 0.6532 - val_loss: 0.6978 - val_accuracy: 0.5454\n",
      "Epoch 174/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6055 - accuracy: 0.6532 - val_loss: 0.7277 - val_accuracy: 0.4946\n",
      "Epoch 175/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6052 - accuracy: 0.6529 - val_loss: 0.6710 - val_accuracy: 0.5751\n",
      "Epoch 176/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6048 - accuracy: 0.6539 - val_loss: 0.6856 - val_accuracy: 0.5487\n",
      "Epoch 177/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6057 - accuracy: 0.6522 - val_loss: 0.6961 - val_accuracy: 0.5679\n",
      "Epoch 178/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6059 - accuracy: 0.6528 - val_loss: 0.6879 - val_accuracy: 0.5766\n",
      "Epoch 179/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6053 - accuracy: 0.6528 - val_loss: 0.7139 - val_accuracy: 0.5190\n",
      "Epoch 180/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6047 - accuracy: 0.6542 - val_loss: 0.6745 - val_accuracy: 0.5865\n",
      "Epoch 181/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6058 - accuracy: 0.6514 - val_loss: 0.7437 - val_accuracy: 0.4716\n",
      "Epoch 182/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6052 - accuracy: 0.6537 - val_loss: 0.7244 - val_accuracy: 0.4914\n",
      "Epoch 183/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6054 - accuracy: 0.6526 - val_loss: 0.6739 - val_accuracy: 0.5923\n",
      "Epoch 184/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6059 - accuracy: 0.6521 - val_loss: 0.6978 - val_accuracy: 0.5422\n",
      "Epoch 185/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6050 - accuracy: 0.6533 - val_loss: 0.7025 - val_accuracy: 0.5434\n",
      "Epoch 186/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6051 - accuracy: 0.6530 - val_loss: 0.7143 - val_accuracy: 0.5377\n",
      "Epoch 187/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6049 - accuracy: 0.6536 - val_loss: 0.7141 - val_accuracy: 0.4982\n",
      "Epoch 188/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6059 - accuracy: 0.6521 - val_loss: 0.6983 - val_accuracy: 0.5399\n",
      "Epoch 189/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6057 - accuracy: 0.6518 - val_loss: 0.6916 - val_accuracy: 0.5456\n",
      "Epoch 190/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6048 - accuracy: 0.6535 - val_loss: 0.6964 - val_accuracy: 0.5397\n",
      "Epoch 191/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6053 - accuracy: 0.6534 - val_loss: 0.6949 - val_accuracy: 0.5594\n",
      "Epoch 192/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6058 - accuracy: 0.6521 - val_loss: 0.7164 - val_accuracy: 0.4887\n",
      "Epoch 193/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6053 - accuracy: 0.6531 - val_loss: 0.7127 - val_accuracy: 0.5267\n",
      "Epoch 194/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6054 - accuracy: 0.6526 - val_loss: 0.7255 - val_accuracy: 0.5035\n",
      "Epoch 195/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6054 - accuracy: 0.6522 - val_loss: 0.7258 - val_accuracy: 0.4876\n",
      "Epoch 196/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6046 - accuracy: 0.6544 - val_loss: 0.6823 - val_accuracy: 0.5509\n",
      "Epoch 197/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6059 - accuracy: 0.6524 - val_loss: 0.7196 - val_accuracy: 0.5149\n",
      "Epoch 198/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6052 - accuracy: 0.6533 - val_loss: 0.7099 - val_accuracy: 0.5368\n",
      "Epoch 199/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6051 - accuracy: 0.6527 - val_loss: 0.6925 - val_accuracy: 0.5624\n",
      "Epoch 200/200\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.6045 - accuracy: 0.6542 - val_loss: 0.7176 - val_accuracy: 0.5093\n",
      "[I 2020-10-21 08:47:41,800] Trial 0 finished with value: 0.4907280206680298 and parameters: {'units1': 494.0, 'units2': 322.0, 'lr': 0.09}. Best is trial 0 with value: 0.4907280206680298.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "lr : 0.09\n",
      "units1 : 494.0\n",
      "units2 : 322.0\n"
     ]
    }
   ],
   "source": [
    "sorted_best_params = sorted(study.best_params.items(), key=lambda x : x[0])\n",
    "best_param = dict()\n",
    "for i, k in sorted_best_params:\n",
    "    print(i + ' : ' + str(k))\n",
    "    best_param[i] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "# Keras以外を利用するのも一つの手段。\n",
    "model = keras.models.Sequential()\n",
    "model.add(Dense(units=best_param[\"units1\"], activation=tf.nn.relu)) \n",
    "# model.add(Dropout(0.5))\n",
    "model.add(keras.layers.BatchNormalization())  # バッチ正規化層\n",
    "model.add(Dense(units=best_param[\"units2\"], activation=tf.nn.relu)) \n",
    "# model.add(Dropout(0.5))\n",
    "model.add(keras.layers.BatchNormalization())  # バッチ正規化層\n",
    "model.add(Dense(units=2, activation=tf.nn.softmax))  # 出力層（活性化関数はソフトマックス関数）\n",
    "model.compile(optimizer = keras.optimizers.SGD(lr=0.01),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " val_accuracy: 0.6456\n",
      "Epoch 62/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6110 - accuracy: 0.6472 - val_loss: 0.6113 - val_accuracy: 0.6700\n",
      "Epoch 63/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6113 - accuracy: 0.6458 - val_loss: 0.6093 - val_accuracy: 0.6872\n",
      "Epoch 64/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6112 - accuracy: 0.6464 - val_loss: 0.7118 - val_accuracy: 0.5040\n",
      "Epoch 65/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6111 - accuracy: 0.6469 - val_loss: 0.6165 - val_accuracy: 0.6746\n",
      "Epoch 66/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6113 - accuracy: 0.6469 - val_loss: 0.6300 - val_accuracy: 0.6505\n",
      "Epoch 67/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6109 - accuracy: 0.6464 - val_loss: 0.6505 - val_accuracy: 0.6213\n",
      "Epoch 68/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6108 - accuracy: 0.6471 - val_loss: 0.6233 - val_accuracy: 0.6775\n",
      "Epoch 69/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6112 - accuracy: 0.6464 - val_loss: 0.6422 - val_accuracy: 0.6396\n",
      "Epoch 70/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6107 - accuracy: 0.6468 - val_loss: 0.6661 - val_accuracy: 0.5745\n",
      "Epoch 71/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6105 - accuracy: 0.6476 - val_loss: 0.5978 - val_accuracy: 0.6825\n",
      "Epoch 72/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6106 - accuracy: 0.6471 - val_loss: 0.6474 - val_accuracy: 0.6268\n",
      "Epoch 73/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6109 - accuracy: 0.6465 - val_loss: 0.6808 - val_accuracy: 0.5767\n",
      "Epoch 74/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6109 - accuracy: 0.6462 - val_loss: 0.6134 - val_accuracy: 0.6793\n",
      "Epoch 75/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6107 - accuracy: 0.6471 - val_loss: 0.6072 - val_accuracy: 0.6952\n",
      "Epoch 76/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6111 - accuracy: 0.6467 - val_loss: 0.6500 - val_accuracy: 0.6072\n",
      "Epoch 77/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6105 - accuracy: 0.6471 - val_loss: 0.6495 - val_accuracy: 0.6389\n",
      "Epoch 78/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6105 - accuracy: 0.6472 - val_loss: 0.6521 - val_accuracy: 0.5977\n",
      "Epoch 79/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6105 - accuracy: 0.6474 - val_loss: 0.6462 - val_accuracy: 0.6318\n",
      "Epoch 80/200\n",
      "47/47 [==============================] - 1s 22ms/step - loss: 0.6108 - accuracy: 0.6470 - val_loss: 0.6921 - val_accuracy: 0.5609\n",
      "Epoch 81/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6102 - accuracy: 0.6470 - val_loss: 0.6569 - val_accuracy: 0.5720\n",
      "Epoch 82/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6104 - accuracy: 0.6470 - val_loss: 0.6174 - val_accuracy: 0.6861\n",
      "Epoch 83/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6105 - accuracy: 0.6467 - val_loss: 0.6852 - val_accuracy: 0.5641\n",
      "Epoch 84/200\n",
      "47/47 [==============================] - 1s 22ms/step - loss: 0.6103 - accuracy: 0.6478 - val_loss: 0.6441 - val_accuracy: 0.6288\n",
      "Epoch 85/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6102 - accuracy: 0.6474 - val_loss: 0.6466 - val_accuracy: 0.6300\n",
      "Epoch 86/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6102 - accuracy: 0.6471 - val_loss: 0.6303 - val_accuracy: 0.6427\n",
      "Epoch 87/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6100 - accuracy: 0.6480 - val_loss: 0.6227 - val_accuracy: 0.6727\n",
      "Epoch 88/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6104 - accuracy: 0.6468 - val_loss: 0.7049 - val_accuracy: 0.5046\n",
      "Epoch 89/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6098 - accuracy: 0.6481 - val_loss: 0.6403 - val_accuracy: 0.6342\n",
      "Epoch 90/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6106 - accuracy: 0.6470 - val_loss: 0.6521 - val_accuracy: 0.6028\n",
      "Epoch 91/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6100 - accuracy: 0.6477 - val_loss: 0.6876 - val_accuracy: 0.5452\n",
      "Epoch 92/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6098 - accuracy: 0.6481 - val_loss: 0.6979 - val_accuracy: 0.5481\n",
      "Epoch 93/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6099 - accuracy: 0.6480 - val_loss: 0.6302 - val_accuracy: 0.6551\n",
      "Epoch 94/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6101 - accuracy: 0.6475 - val_loss: 0.6605 - val_accuracy: 0.5975\n",
      "Epoch 95/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6098 - accuracy: 0.6478 - val_loss: 0.6930 - val_accuracy: 0.5439\n",
      "Epoch 96/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6100 - accuracy: 0.6473 - val_loss: 0.6373 - val_accuracy: 0.6636\n",
      "Epoch 97/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6104 - accuracy: 0.6468 - val_loss: 0.6358 - val_accuracy: 0.6470\n",
      "Epoch 98/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6101 - accuracy: 0.6475 - val_loss: 0.7268 - val_accuracy: 0.5167\n",
      "Epoch 99/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6102 - accuracy: 0.6473 - val_loss: 0.6772 - val_accuracy: 0.5648\n",
      "Epoch 100/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6102 - accuracy: 0.6473 - val_loss: 0.6786 - val_accuracy: 0.5753\n",
      "Epoch 101/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6101 - accuracy: 0.6475 - val_loss: 0.6829 - val_accuracy: 0.5552\n",
      "Epoch 102/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6095 - accuracy: 0.6483 - val_loss: 0.6637 - val_accuracy: 0.5879\n",
      "Epoch 103/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6097 - accuracy: 0.6477 - val_loss: 0.6553 - val_accuracy: 0.6180\n",
      "Epoch 104/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6102 - accuracy: 0.6473 - val_loss: 0.6326 - val_accuracy: 0.6336\n",
      "Epoch 105/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6094 - accuracy: 0.6485 - val_loss: 0.6766 - val_accuracy: 0.5930\n",
      "Epoch 106/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6098 - accuracy: 0.6481 - val_loss: 0.6611 - val_accuracy: 0.5979\n",
      "Epoch 107/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6098 - accuracy: 0.6479 - val_loss: 0.6624 - val_accuracy: 0.6113\n",
      "Epoch 108/200\n",
      "47/47 [==============================] - 1s 22ms/step - loss: 0.6094 - accuracy: 0.6488 - val_loss: 0.6770 - val_accuracy: 0.5796\n",
      "Epoch 109/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6104 - accuracy: 0.6474 - val_loss: 0.6523 - val_accuracy: 0.6292\n",
      "Epoch 110/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6097 - accuracy: 0.6475 - val_loss: 0.6683 - val_accuracy: 0.5813\n",
      "Epoch 111/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6098 - accuracy: 0.6473 - val_loss: 0.6375 - val_accuracy: 0.6525\n",
      "Epoch 112/200\n",
      "47/47 [==============================] - 1s 24ms/step - loss: 0.6092 - accuracy: 0.6486 - val_loss: 0.6713 - val_accuracy: 0.5860\n",
      "Epoch 113/200\n",
      "47/47 [==============================] - 1s 22ms/step - loss: 0.6099 - accuracy: 0.6475 - val_loss: 0.6401 - val_accuracy: 0.6269\n",
      "Epoch 114/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6096 - accuracy: 0.6477 - val_loss: 0.6484 - val_accuracy: 0.6053\n",
      "Epoch 115/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6096 - accuracy: 0.6477 - val_loss: 0.6547 - val_accuracy: 0.5993\n",
      "Epoch 116/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6095 - accuracy: 0.6486 - val_loss: 0.6660 - val_accuracy: 0.5930\n",
      "Epoch 117/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6100 - accuracy: 0.6482 - val_loss: 0.6598 - val_accuracy: 0.6064\n",
      "Epoch 118/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6091 - accuracy: 0.6491 - val_loss: 0.6184 - val_accuracy: 0.6843\n",
      "Epoch 119/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6100 - accuracy: 0.6469 - val_loss: 0.6051 - val_accuracy: 0.6935\n",
      "Epoch 120/200\n",
      "47/47 [==============================] - 1s 22ms/step - loss: 0.6095 - accuracy: 0.6479 - val_loss: 0.6484 - val_accuracy: 0.5845\n",
      "Epoch 121/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6093 - accuracy: 0.6486 - val_loss: 0.6722 - val_accuracy: 0.5764\n",
      "Epoch 122/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6091 - accuracy: 0.6487 - val_loss: 0.6457 - val_accuracy: 0.6217\n",
      "Epoch 123/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6090 - accuracy: 0.6485 - val_loss: 0.6809 - val_accuracy: 0.5759\n",
      "Epoch 124/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6097 - accuracy: 0.6481 - val_loss: 0.6257 - val_accuracy: 0.6752\n",
      "Epoch 125/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6094 - accuracy: 0.6480 - val_loss: 0.6556 - val_accuracy: 0.6211\n",
      "Epoch 126/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6092 - accuracy: 0.6488 - val_loss: 0.6463 - val_accuracy: 0.6106\n",
      "Epoch 127/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6099 - accuracy: 0.6473 - val_loss: 0.6777 - val_accuracy: 0.5552\n",
      "Epoch 128/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6095 - accuracy: 0.6479 - val_loss: 0.6480 - val_accuracy: 0.6135\n",
      "Epoch 129/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6106 - accuracy: 0.6467 - val_loss: 0.7485 - val_accuracy: 0.4919\n",
      "Epoch 130/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6096 - accuracy: 0.6475 - val_loss: 0.6238 - val_accuracy: 0.6625\n",
      "Epoch 131/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6087 - accuracy: 0.6488 - val_loss: 0.6589 - val_accuracy: 0.5973\n",
      "Epoch 132/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6096 - accuracy: 0.6480 - val_loss: 0.6617 - val_accuracy: 0.5819\n",
      "Epoch 133/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6089 - accuracy: 0.6490 - val_loss: 0.7054 - val_accuracy: 0.5191\n",
      "Epoch 134/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6094 - accuracy: 0.6478 - val_loss: 0.6416 - val_accuracy: 0.6083\n",
      "Epoch 135/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6095 - accuracy: 0.6472 - val_loss: 0.6408 - val_accuracy: 0.6464\n",
      "Epoch 136/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6094 - accuracy: 0.6477 - val_loss: 0.6714 - val_accuracy: 0.5920\n",
      "Epoch 137/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6092 - accuracy: 0.6481 - val_loss: 0.6720 - val_accuracy: 0.5581\n",
      "Epoch 138/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6092 - accuracy: 0.6487 - val_loss: 0.6271 - val_accuracy: 0.6517\n",
      "Epoch 139/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6085 - accuracy: 0.6495 - val_loss: 0.6516 - val_accuracy: 0.6115\n",
      "Epoch 140/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6091 - accuracy: 0.6482 - val_loss: 0.6961 - val_accuracy: 0.5463\n",
      "Epoch 141/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6099 - accuracy: 0.6468 - val_loss: 0.6555 - val_accuracy: 0.6204\n",
      "Epoch 142/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6087 - accuracy: 0.6491 - val_loss: 0.6363 - val_accuracy: 0.6613\n",
      "Epoch 143/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6087 - accuracy: 0.6490 - val_loss: 0.6034 - val_accuracy: 0.6720\n",
      "Epoch 144/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6085 - accuracy: 0.6496 - val_loss: 0.6796 - val_accuracy: 0.5467\n",
      "Epoch 145/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6099 - accuracy: 0.6474 - val_loss: 0.6262 - val_accuracy: 0.6505\n",
      "Epoch 146/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6083 - accuracy: 0.6492 - val_loss: 0.6242 - val_accuracy: 0.6648\n",
      "Epoch 147/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6095 - accuracy: 0.6483 - val_loss: 0.6398 - val_accuracy: 0.6485\n",
      "Epoch 148/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6086 - accuracy: 0.6488 - val_loss: 0.6143 - val_accuracy: 0.6662\n",
      "Epoch 149/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6105 - accuracy: 0.6460 - val_loss: 0.6233 - val_accuracy: 0.6572\n",
      "Epoch 150/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6089 - accuracy: 0.6479 - val_loss: 0.6713 - val_accuracy: 0.5844\n",
      "Epoch 151/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6090 - accuracy: 0.6480 - val_loss: 0.6277 - val_accuracy: 0.6442\n",
      "Epoch 152/200\n",
      "47/47 [==============================] - 1s 22ms/step - loss: 0.6083 - accuracy: 0.6498 - val_loss: 0.6366 - val_accuracy: 0.6230\n",
      "Epoch 153/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6088 - accuracy: 0.6493 - val_loss: 0.6854 - val_accuracy: 0.5453\n",
      "Epoch 154/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6092 - accuracy: 0.6486 - val_loss: 0.6617 - val_accuracy: 0.5945\n",
      "Epoch 155/200\n",
      "47/47 [==============================] - 1s 22ms/step - loss: 0.6088 - accuracy: 0.6485 - val_loss: 0.6243 - val_accuracy: 0.6663\n",
      "Epoch 156/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6080 - accuracy: 0.6501 - val_loss: 0.6528 - val_accuracy: 0.5953\n",
      "Epoch 157/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6089 - accuracy: 0.6487 - val_loss: 0.6778 - val_accuracy: 0.5681\n",
      "Epoch 158/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6087 - accuracy: 0.6495 - val_loss: 0.6885 - val_accuracy: 0.5482\n",
      "Epoch 159/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6084 - accuracy: 0.6496 - val_loss: 0.6519 - val_accuracy: 0.6284\n",
      "Epoch 160/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6081 - accuracy: 0.6497 - val_loss: 0.6608 - val_accuracy: 0.6020\n",
      "Epoch 161/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6092 - accuracy: 0.6482 - val_loss: 0.6538 - val_accuracy: 0.5858\n",
      "Epoch 162/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6094 - accuracy: 0.6482 - val_loss: 0.6203 - val_accuracy: 0.6671\n",
      "Epoch 163/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6095 - accuracy: 0.6472 - val_loss: 0.6680 - val_accuracy: 0.6001\n",
      "Epoch 164/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6090 - accuracy: 0.6485 - val_loss: 0.6823 - val_accuracy: 0.5708\n",
      "Epoch 165/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6084 - accuracy: 0.6495 - val_loss: 0.6570 - val_accuracy: 0.6175\n",
      "Epoch 166/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6084 - accuracy: 0.6497 - val_loss: 0.6696 - val_accuracy: 0.5933\n",
      "Epoch 167/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6089 - accuracy: 0.6483 - val_loss: 0.6430 - val_accuracy: 0.6406\n",
      "Epoch 168/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6088 - accuracy: 0.6490 - val_loss: 0.6893 - val_accuracy: 0.5868\n",
      "Epoch 169/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6084 - accuracy: 0.6491 - val_loss: 0.7092 - val_accuracy: 0.5398\n",
      "Epoch 170/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6082 - accuracy: 0.6493 - val_loss: 0.6565 - val_accuracy: 0.6078\n",
      "Epoch 171/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6080 - accuracy: 0.6493 - val_loss: 0.6655 - val_accuracy: 0.5842\n",
      "Epoch 172/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6086 - accuracy: 0.6487 - val_loss: 0.6572 - val_accuracy: 0.6035\n",
      "Epoch 173/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6084 - accuracy: 0.6489 - val_loss: 0.7024 - val_accuracy: 0.5420\n",
      "Epoch 174/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6087 - accuracy: 0.6485 - val_loss: 0.7094 - val_accuracy: 0.5372\n",
      "Epoch 175/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6090 - accuracy: 0.6486 - val_loss: 0.6077 - val_accuracy: 0.6671\n",
      "Epoch 176/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6085 - accuracy: 0.6490 - val_loss: 0.6873 - val_accuracy: 0.5528\n",
      "Epoch 177/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6082 - accuracy: 0.6492 - val_loss: 0.6055 - val_accuracy: 0.6660\n",
      "Epoch 178/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6085 - accuracy: 0.6492 - val_loss: 0.5790 - val_accuracy: 0.7428\n",
      "Epoch 179/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6095 - accuracy: 0.6476 - val_loss: 0.6872 - val_accuracy: 0.5565\n",
      "Epoch 180/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6088 - accuracy: 0.6481 - val_loss: 0.6445 - val_accuracy: 0.6306\n",
      "Epoch 181/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6087 - accuracy: 0.6488 - val_loss: 0.6871 - val_accuracy: 0.5571\n",
      "Epoch 182/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6090 - accuracy: 0.6485 - val_loss: 0.6978 - val_accuracy: 0.5493\n",
      "Epoch 183/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6084 - accuracy: 0.6489 - val_loss: 0.6312 - val_accuracy: 0.6704\n",
      "Epoch 184/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6082 - accuracy: 0.6494 - val_loss: 0.6434 - val_accuracy: 0.6251\n",
      "Epoch 185/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6085 - accuracy: 0.6490 - val_loss: 0.6208 - val_accuracy: 0.6636\n",
      "Epoch 186/200\n",
      "47/47 [==============================] - 1s 22ms/step - loss: 0.6088 - accuracy: 0.6484 - val_loss: 0.6760 - val_accuracy: 0.5539\n",
      "Epoch 187/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6079 - accuracy: 0.6502 - val_loss: 0.6568 - val_accuracy: 0.5951\n",
      "Epoch 188/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6084 - accuracy: 0.6491 - val_loss: 0.6402 - val_accuracy: 0.6379\n",
      "Epoch 189/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6090 - accuracy: 0.6477 - val_loss: 0.6361 - val_accuracy: 0.6214\n",
      "Epoch 190/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6088 - accuracy: 0.6482 - val_loss: 0.6724 - val_accuracy: 0.5441\n",
      "Epoch 191/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6087 - accuracy: 0.6485 - val_loss: 0.6511 - val_accuracy: 0.6279\n",
      "Epoch 192/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6083 - accuracy: 0.6490 - val_loss: 0.6819 - val_accuracy: 0.5585\n",
      "Epoch 193/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6082 - accuracy: 0.6499 - val_loss: 0.7068 - val_accuracy: 0.5496\n",
      "Epoch 194/200\n",
      "47/47 [==============================] - 1s 22ms/step - loss: 0.6086 - accuracy: 0.6492 - val_loss: 0.6511 - val_accuracy: 0.5897\n",
      "Epoch 195/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6083 - accuracy: 0.6490 - val_loss: 0.6386 - val_accuracy: 0.6404\n",
      "Epoch 196/200\n",
      "47/47 [==============================] - 1s 22ms/step - loss: 0.6080 - accuracy: 0.6500 - val_loss: 0.6259 - val_accuracy: 0.6679\n",
      "Epoch 197/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6077 - accuracy: 0.6502 - val_loss: 0.6301 - val_accuracy: 0.6278\n",
      "Epoch 198/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6090 - accuracy: 0.6484 - val_loss: 0.6593 - val_accuracy: 0.6066\n",
      "Epoch 199/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6079 - accuracy: 0.6503 - val_loss: 0.7044 - val_accuracy: 0.5350\n",
      "Epoch 200/200\n",
      "47/47 [==============================] - 1s 23ms/step - loss: 0.6083 - accuracy: 0.6489 - val_loss: 0.6570 - val_accuracy: 0.5759\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = X_res,\n",
    "        y = y_res,\n",
    "        batch_size = 8192, # バッチサイズ\n",
    "        # epochs = 100, # エポック数\n",
    "        epochs = 200, # エポック数\n",
    "        validation_split = 0.05, # 検証データの割合\n",
    "        # callbacks = [es_cb], # 早期終了の設定\n",
    "        verbose = 1) # 進捗の確認を行うか（0:行わない, 1:行う）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch数による正解率の推移を描画。\n",
    "# ※大体200で均衡状態になるっぽいのでソースとしては用済み。\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# #% matplotlib inline\n",
    "# x = range(int(best_param[\"epochs\"]))  # 演習D epoch数をx軸に指定する。range()の()のなかに、数字を入力してください。数字はepochsで指定した数と同じにしてください。\n",
    "# plt.plot(x, history.history[\"accuracy\"], c=\"red\")\n",
    "# plt.plot(x, history.history[\"val_accuracy\"], c=\"blue\")\n",
    "# plt.title(\"accuracy\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[140015  59779]\n",
      " [ 83983 115811]]\n"
     ]
    }
   ],
   "source": [
    "# 混同行列による評価\n",
    "y_proba = model.predict(X_res)\n",
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "confmat = confusion_matrix(y_res, y_pred)\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "正解率: 0.640224431164099\n"
     ]
    }
   ],
   "source": [
    "# 正答率による評価\n",
    "print(\"正解率:\", accuracy_score(y_res, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   y  y_pred\n",
      "0  0       0\n",
      "1  1       0\n",
      "2  0       0\n",
      "3  0       0\n",
      "4  0       1\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame({'y': y_res, 'y_pred': y_pred}).head())  # 実際のクラスと分類結果を上から5つだけ表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "回帰係数:\n",
      "                         Name  Coefficients\n",
      "3                       grade     -0.168507\n",
      "5                credit_score     -0.064070\n",
      "4           employment_length      0.005284\n",
      "7  purpose_debt_consolidation      0.018229\n",
      "0                   loan_amnt      0.031944\n",
      "6            application_type      0.040122\n",
      "1                        term      0.045696\n",
      "2               interest_rate      0.533368\n",
      "切片: -0.025510445\n",
      "決定係数: 0.07914761039345974\n"
     ]
    }
   ],
   "source": [
    "# 重回帰\n",
    "# 説明変数の重みを確認\n",
    "from sklearn import linear_model  # 線形回帰を行うためのモジュール\n",
    "# 変数の準備\n",
    "# X = data_oh.drop([\"loan_status_ChargedOff\", \"loan_status_FullyPaid\"], axis=1)  # 説明変数の設定\n",
    "# y = data_oh[\"loan_status_FullyPaid\"]  # 目的変数の設定\n",
    "\n",
    "# 学習\n",
    "lr = linear_model.LinearRegression()  # 線形回帰モデルのインスタンスを作成\n",
    "lr.fit(X_train, y_train)  # 回帰の実行\n",
    "\n",
    "# 結果の確認\n",
    "print(\"回帰係数:\")\n",
    "print(pd.DataFrame({\"Name\": X_train.columns,\n",
    "                    \"Coefficients\": lr.coef_}).sort_values(by='Coefficients'))  # 回帰係数\n",
    "print(\"切片:\", lr.intercept_)  # 切片\n",
    "print(\"決定係数:\", lr.score(X_train, y_train))  # 決定係数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   loan_amnt  term  interest_rate     grade  employment_length  credit_score  \\\n",
       "0   0.080922   0.0       0.121977  0.137931                0.0      0.382933   \n",
       "1   0.243609   1.0       0.205691  0.172414                1.0      0.276126   \n",
       "2   0.105436   0.0       0.404861  0.379310                0.1      0.006498   \n",
       "3   0.117513   0.0       0.384088  0.344828                0.0      0.016213   \n",
       "4   0.373746   1.0       0.875957  0.827586                1.0      0.049292   \n",
       "\n",
       "   application_type  purpose_debt_consolidation  \n",
       "0               1.0                         1.0  \n",
       "1               1.0                         0.0  \n",
       "2               1.0                         1.0  \n",
       "3               1.0                         0.0  \n",
       "4               1.0                         1.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>term</th>\n      <th>interest_rate</th>\n      <th>grade</th>\n      <th>employment_length</th>\n      <th>credit_score</th>\n      <th>application_type</th>\n      <th>purpose_debt_consolidation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.080922</td>\n      <td>0.0</td>\n      <td>0.121977</td>\n      <td>0.137931</td>\n      <td>0.0</td>\n      <td>0.382933</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.243609</td>\n      <td>1.0</td>\n      <td>0.205691</td>\n      <td>0.172414</td>\n      <td>1.0</td>\n      <td>0.276126</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.105436</td>\n      <td>0.0</td>\n      <td>0.404861</td>\n      <td>0.379310</td>\n      <td>0.1</td>\n      <td>0.006498</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.117513</td>\n      <td>0.0</td>\n      <td>0.384088</td>\n      <td>0.344828</td>\n      <td>0.0</td>\n      <td>0.016213</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.373746</td>\n      <td>1.0</td>\n      <td>0.875957</td>\n      <td>0.827586</td>\n      <td>1.0</td>\n      <td>0.049292</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ランダムフォレスト\n",
    "# # データ前処理\n",
    "# # データ分割\n",
    "# X = data.drop([\"id\", \"term\", \"grade\", \"employment_length\", \"purpose\", \"application_type\", \"loan_status\"], axis=1)\n",
    "# y_train = data[\"loan_status\"].values\n",
    "# # # Min-Maxスケーリング\n",
    "# X = ((X - X.min()) / (X.max() - X.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   y  y_pred\n",
      "0  0       0\n",
      "1  1       0\n",
      "2  0       1\n",
      "3  0       1\n",
      "4  0       1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier  # ランダムフォレストを実行するためのクラス\n",
    "# 学習\n",
    "RFC = RandomForestClassifier(max_depth=3, random_state=1)  # ランダムフォレストのインスタンスを作成\n",
    "RFC.fit(X_res, y_res)  # ランダムフォレストの学習\n",
    "\n",
    "# 分類結果の確認\n",
    "y_pred = RFC.predict(X_res)  # 分類結果\n",
    "print(pd.DataFrame({'y': y_res, 'y_pred': y_pred}).head())  # 実際のクラスと分類結果を上から5つだけ表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "正解率: 0.6400417429952852\n"
     ]
    }
   ],
   "source": [
    "# コード例2\n",
    "# モデルの精度（正解率）の確認\n",
    "print('正解率:', RFC.score(X_res, y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[113760  86034]\n",
      " [ 57801 141993]]\n"
     ]
    }
   ],
   "source": [
    "# 混同行列による評価\n",
    "y_proba = RFC.predict(X_res)\n",
    "confmat = confusion_matrix(y_res, y_proba)\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history.history[\"val_accuracy\"]\n",
    "np.savetxt(\"C:\\work\\AI\\hoge.dat\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ前処理\n",
    "data_test = pd.read_csv(\"test.csv\")\n",
    "# Chapter3\n",
    "# データ前処理\n",
    "# One-Hotエンコーディング\n",
    "# pre_X = input_data.drop([\"loan_status\", \"id\"], axis=1).replace({\n",
    "# IDは消す。グレード、勤続年数は順番付け。\n",
    "# 登録方式は1/0。用途は「やばそうな理由」だけフラグ立て。\n",
    "pre_X = data_test.drop([\"id\"], axis=1).replace({\n",
    "    \"A1\": 1, \"A2\": 2, \"A3\": 3, \"A4\": 4, \"A5\": 5,\n",
    "    \"B1\": 6, \"B2\": 7, \"B3\": 8, \"B4\": 9, \"B5\": 10,\n",
    "    \"C1\": 11, \"C2\": 12, \"C3\": 13, \"C4\": 14, \"C5\": 15,\n",
    "    \"D1\": 16, \"D2\": 17, \"D3\": 18, \"D4\": 19, \"D5\": 20,\n",
    "    \"E1\": 21, \"E2\": 22, \"E3\": 23, \"E4\": 24, \"E5\": 25,\n",
    "    \"F1\": 26, \"F2\": 27, \"F3\": 28, \"F4\": 29, \"F5\": 30,\n",
    "    \"0 year\": 0, \"0 years\": 0, \"1 years\": 1, \"1 year\": 1, \"2 years\": 2, \"3 years\": 3, \"4 years\": 4, \"5 years\": 5,\n",
    "    \"6 years\": 6, \"7 years\": 7, \"8 years\": 8, \"9 years\": 9, \"10 years\": 10,\n",
    "    \"Individual\": 1, \"Joint App\": 0,\n",
    "    \"purpose_car\": 0,\"purpose_credit_card\": 1,\"purpose_debt_consolidation\": 1,\"purpose_home_improvement\": 0,\"purpose_house\": 0,\"purpose_major_purchase\": 0,\"purpose_medical\": 0,\"purpose_other\": 0,\"purpose_small_business\": 0,\n",
    "}).astype({\n",
    "    \"term\": \"int8\",\n",
    "    \"grade\": \"int8\",\n",
    "    \"employment_length\": \"int8\",\n",
    "    \"application_type\": \"int8\",\n",
    "})\n",
    "X = pd.get_dummies(pre_X)\n",
    "\n",
    "# 加工が終わった時点でCSVに出すと、ほかのモデルでの使いまわしがきく。\n",
    "X_test = ((X - X.min()) / (X.max() - X.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 借入理由を債務整理のみに限定。フラグ系をINTに変換\n",
    "X_test = X_test.astype(\"float32\")\n",
    "X_test = X_test.drop([\"purpose_home_improvement\", \"purpose_house\", \"purpose_major_purchase\", \"purpose_medical\", \"purpose_other\", \"purpose_small_business\", \"purpose_car\", \"purpose_credit_card\", \"purpose_moving\"], axis=1).astype({\n",
    "    \"term\": \"int8\",\n",
    "    \"grade\": \"int8\",\n",
    "    \"employment_length\": \"int8\",\n",
    "    \"application_type\": \"int8\",\n",
    "    \"purpose_debt_consolidation\": \"int8\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   loan_amnt  term  interest_rate  grade  employment_length  credit_score  \\\n",
       "0   0.233748     0       0.338255      0                  1      0.170125   \n",
       "1   0.550417     1       0.388391      0                  1      0.081955   \n",
       "2   0.528645     0       0.117750      0                  1      0.306207   \n",
       "3   0.048324     0       0.055643      0                  0      0.484529   \n",
       "4   0.563678     0       0.271754      0                  0      0.274790   \n",
       "\n",
       "   application_type  purpose_debt_consolidation  \n",
       "0                 1                           0  \n",
       "1                 1                           1  \n",
       "2                 1                           0  \n",
       "3                 1                           1  \n",
       "4                 1                           1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loan_amnt</th>\n      <th>term</th>\n      <th>interest_rate</th>\n      <th>grade</th>\n      <th>employment_length</th>\n      <th>credit_score</th>\n      <th>application_type</th>\n      <th>purpose_debt_consolidation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.233748</td>\n      <td>0</td>\n      <td>0.338255</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.170125</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.550417</td>\n      <td>1</td>\n      <td>0.388391</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.081955</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.528645</td>\n      <td>0</td>\n      <td>0.117750</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.306207</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.048324</td>\n      <td>0</td>\n      <td>0.055643</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.484529</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.563678</td>\n      <td>0</td>\n      <td>0.271754</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.274790</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RFC.predict(X_test)\n",
    "np.savetxt(\"C:\\work\\AI\\hoge2.dat\", y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = model.predict(X_test)\n",
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "np.savetxt(\"C:\\work\\AI\\hoge.dat\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}